{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import everything now..."},{"metadata":{},"cell_type":"markdown","source":"より良くするなら...  \n- lagtimeをtask_container_idごとに作り直す"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nimport copy\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import QuantileTransformer\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configure constants"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    MAX_SEQ = 100 \n    EMBED_DIMS = 512 \n    HEADS = 8\n    NUM_ENCODER = NUM_DECODER = 2 # 4\n    BATCH_SIZE = 256 # 64\n    TRAIN_FILE = \"../input/riiid-test-answer-prediction/train.csv\"\n    TOTAL_EXE = 13523\n    TOTAL_CAT = 8 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RiiidDataset(Dataset):\n    def __init__(self,samples,max_seq,start_token=0): \n        super().__init__()\n        self.samples = samples\n        self.max_seq = max_seq\n        self.start_token = start_token\n        self.data = []\n        for id in self.samples.index:\n            exe_ids,answers,ela_time,lagtimes,parts = self.samples[id]\n            if len(exe_ids)>max_seq:\n                for l in range((len(exe_ids)+max_seq-1)//max_seq):\n                    self.data.append((exe_ids[l:l+max_seq],answers[l:l+max_seq],ela_time[l:l+max_seq],lagtimes[l:l+max_seq],parts[l:l+max_seq]))\n            elif len(exe_ids)<self.max_seq and len(exe_ids)>10:\n                self.data.append((exe_ids,answers,ela_time,lagtimes,parts))\n            else :\n                continue\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        question_ids,answers,ela_time,l_time,part = self.data[idx]\n        seq_len = len(question_ids)\n\n        # 長さが足りない部分はpadding(0埋め)されている\n        exe_ids = np.zeros(self.max_seq,dtype=int)\n        ans = np.zeros(self.max_seq,dtype=int)\n        elapsed_time = np.zeros(self.max_seq,dtype=int)\n        lagtime = np.zeros(self.max_seq,dtype=int)\n        exe_part = np.zeros(self.max_seq,dtype=int)\n        if seq_len<self.max_seq:\n            # 後ろ詰め\n            exe_ids[-seq_len:] = question_ids\n            ans[-seq_len:] = answers\n            elapsed_time[-seq_len:] = ela_time\n            lagtime[-seq_len:] = l_time\n            exe_part[-seq_len:] = part\n        else:\n            exe_ids[:] = question_ids[-self.max_seq:]\n            ans[:] = answers[-self.max_seq:]\n            elapsed_time[:] = ela_time[-self.max_seq:]\n            lagtime[:] = l_time[-self.max_seq:]\n            exe_part[:] = part[-self.max_seq:]\n\n        input_ela_time = np.zeros(self.max_seq,dtype=int)\n        input_ela_time = np.insert(elapsed_time,0,self.start_token) # np.insert(配列、挿入位置、挿入値)\n        input_ela_time = np.delete(input_ela_time,-1) # np.delete(配列、削除位置)\n        \n        input_lag_time = np.zeros(self.max_seq,dtype=int)\n        input_lag_time = np.insert(lagtime,0,self.start_token)\n        input_lag_time = np.delete(input_lag_time,-1)\n\n        inputs = {\n            \"input_ids\":exe_ids,\n            \"input_ela_time\":input_ela_time.astype(np.int),\n            \"input_lag_time\":input_lag_time.astype(np.int),\n            \"input_part\":exe_part\n        }\n        answers = np.append([0],ans[:-1]) #start token\n        assert ans.shape[0]==answers.shape[0] and answers.shape[0]==input_ela_time.shape[0] and answers.shape[0]==input_lag_time.shape[0], \"both ans and label should be same len with start-token\"\n        return inputs,answers,ans\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SAINT+ model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self,in_feat):\n        super(FFN,self).__init__()\n        self.linear1 = nn.Linear(in_feat,in_feat)\n        self.linear2 = nn.Linear(in_feat,in_feat)\n        self.drop = nn.Dropout(0.2)\n  \n    def forward(self,x):\n        out = F.relu(self.drop(self.linear1(x)))\n        out = self.linear2(out)\n        return out \n\n\nclass EncoderEmbedding(nn.Module):\n    \"\"\"SAINTでは、エンコーダーでは演習情報しか利用しない\"\"\"\n    def __init__(self,n_exercises,n_parts,n_dims,seq_len):\n        super(EncoderEmbedding,self).__init__()\n        self.n_dims = n_dims\n        self.seq_len = seq_len\n        # 演習情報についてembedding（演習ID、パートID、positional encoding）\n        self.exercise_embed = nn.Embedding(n_exercises,n_dims)\n        self.part_embed = nn.Embedding(n_parts,n_dims)\n        self.position_embed = nn.Embedding(seq_len,n_dims)\n\n    def forward(self,exercises,parts):\n        e = self.exercise_embed(exercises)\n        c = self.part_embed(parts)\n        seq = torch.arange(self.seq_len,device=config.device).unsqueeze(0)\n        p = self.position_embed(seq)\n        return p + c + e\n\nclass DecoderEmbedding(nn.Module):\n    \"\"\"\n    SAINTのデコーダーではレスポンス情報しか利用しない\n    lagtime: categorical embedding,\n    elapsed_time: continuas embedding\n    \"\"\"\n    def __init__(self,n_responses,n_lags,n_dims,seq_len):\n        super(DecoderEmbedding,self).__init__()\n        self.n_dims = n_dims\n        self.seq_len = seq_len\n        # 正解、不正解の羅列が来るので、n_responsesは3(2種類+1)\n        self.response_embed = nn.Embedding(n_responses,n_dims)\n        self.ela_time_embed = nn.Linear(1,n_dims) # continuas embedding\n        self.lagtime_embed = nn.Embedding(n_lags,n_dims)\n        self.position_embed = nn.Embedding(seq_len,n_dims)\n\n    def forward(self,responses,elaps_times,lagtimes):\n        e = self.response_embed(responses)\n        el = self.ela_time_embed(elaps_times)\n        lagtimes = torch.true_divide(lagtimes, 1000)\n        lagtimes = torch.round(lagtimes)\n        lagtimes = torch.where(lagtimes.float() <= 300, lagtimes, torch.tensor(300.0).to(config.device)).long()\n        la = self.lagtime_embed(lagtimes)\n        seq = torch.arange(self.seq_len,device=config.device).unsqueeze(0)\n        p = self.position_embed(seq)\n        return p + e + el + la","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Model with Trainer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def future_mask(seq_length):\n    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n    return torch.from_numpy(future_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main model for training \nclass PlusSAINTModule(pl.LightningModule):\n    def __init__(self):\n        super(PlusSAINTModule,self).__init__()\n        self.loss = nn.BCEWithLogitsLoss()\n        self.transformer = nn.Transformer(nhead=config.HEADS, d_model = config.EMBED_DIMS, num_encoder_layers= config.NUM_ENCODER, num_decoder_layers= config.NUM_DECODER, dropout = 0.2)\n        self.encoder_embedding = EncoderEmbedding(n_exercises=config.TOTAL_EXE,\n                                                  n_parts=config.TOTAL_CAT,\n                                                  n_dims=config.EMBED_DIMS,seq_len=config.MAX_SEQ)\n        self.decoder_embedding = DecoderEmbedding(n_responses=3,\n                                                  n_lags=301,\n                                                  n_dims=config.EMBED_DIMS,\n                                                  seq_len=config.MAX_SEQ)\n        self.layer_normal = nn.LayerNorm(config.EMBED_DIMS)\n        self.ffn = FFN(config.EMBED_DIMS)\n        self.pred = nn.Linear(config.EMBED_DIMS, 1)\n\n    def forward(self,x,y): \n        ids = x[\"input_ids\"].long().to(config.device)\n        part= x['input_part'].long().to(config.device)\n        enc = self.encoder_embedding(exercises=ids,parts=part)\n\n        ela_time= x['input_ela_time'].unsqueeze(-1).float().to(config.device)\n        lag_time= x['input_lag_time'].long().to(config.device)\n        responses=y.long().to(config.device)\n        dec = self.decoder_embedding(responses=responses,elaps_times=ela_time,lagtimes=lag_time)\n\n        enc = enc.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n        dec = dec.permute(1, 0, 2)\n        tmp = enc.size(0)\n        mask = future_mask(tmp)\n        mask = mask.to(config.device)\n        att_output = self.transformer(enc, dec, src_mask=mask, tgt_mask=mask, memory_mask = mask)\n        att_output = self.layer_normal(att_output)\n        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n\n        x = self.ffn(att_output)\n        x = self.layer_normal(x + att_output)\n\n        out = self.pred(x)\n        return out.squeeze()\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(),0.0001)\n  \n    def training_step(self,batch,batch_ids):\n        input,ans,labels = batch\n        target_mask = (input[\"input_ids\"]!=0)\n        out = self(input,ans)\n        loss = self.loss(out.view(-1).float(),labels.view(-1).float()) \n        out = torch.masked_select(out,target_mask)\n        out = torch.sigmoid(out) \n        labels = torch.masked_select(labels,target_mask)    \n        self.log(\"train_loss\",loss,on_step=True,prog_bar=True)\n        return {\"loss\":loss,\"outs\":out,\"labels\":labels}\n  \n    def validation_step(self,batch,batch_ids):\n        input,ans,labels = batch\n        target_mask = (input[\"input_ids\"]!=0)\n        out = self(input,ans)\n        loss = self.loss(out.view(-1).float(),labels.view(-1).float())\n        out = torch.masked_select(out,target_mask)\n        out = torch.sigmoid(out) \n        labels = torch.masked_select(labels,target_mask) \n        self.log(\"val_loss\",loss,on_step=True,prog_bar=True)\n        output = {\"outs\":out,\"labels\":labels}\n        return output\n  \n    def validation_epoch_end(self,validation_ouput): \n        out = torch.cat([i[\"outs\"] for i in validation_ouput]).view(-1) \n        labels = torch.cat([i[\"labels\"] for i in validation_ouput]).view(-1)\n        auc = roc_auc_score(labels.cpu().detach().numpy(),out.cpu().detach().numpy())\n        self.print(\"val auc\",auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_df():\n    # leakの問題考えると、task_container_idで考えるべきだが実装だるくなったので考えない\n    dtypes = {\n        'timestamp': 'int64',\n        'user_id': 'int32' ,\n        'content_id': 'int16',\n        'answered_correctly':'int8',\n        'content_type_id':'int8',\n        'prior_question_elapsed_time':'float32'\n    }\n    print(\"loading csv.....\")\n    train_df = pd.read_csv(config.TRAIN_FILE,usecols=[1,2,3,4,7,8],dtype=dtypes)\n    \n    print('concat part feature')\n    part_df = pd.read_pickle('../input/riiid-train-part/train_df_part.pkl')\n    train_df = pd.concat([train_df, part_df], axis=1)\n    del part_df\n    gc.collect()\n    \n    print(\"shape of dataframe :\",train_df.shape)\n    \n    train_df.prior_question_elapsed_time.fillna(0,inplace=True)\n    train_df.prior_question_elapsed_time /=3600\n    train_df.prior_question_elapsed_time = train_df.prior_question_elapsed_time.astype(np.int)\n    \n    print(\"make feature: lagtime\")\n    train_df['lagtime'] = train_df.groupby(['user_id'])['timestamp'].shift()\n    train_df['lagtime']=train_df['timestamp']-train_df['lagtime']\n    train_df.loc[train_df.lagtime < 0] = 0 # なぜか負の値が入り込んでる（要調査）\n    train_df.loc[train_df.lagtime > 300] = 300\n    train_df['lagtime'].fillna(0, inplace=True)\n    train_df.lagtime=train_df.lagtime.astype('int32')\n    gc.collect()\n\n    print('delete lecture rows')\n    train_df = train_df[train_df.content_type_id==0].reset_index(drop=True)\n    \n    print('del feature: timestamp, content_type_id')\n    train_df.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)\n    gc.collect()\n    \n    n_skills = train_df.content_id.nunique() \n    print(\"no. of skills :\",n_skills)\n    print(\"shape after exlusion:\",train_df.shape)\n    return train_df\n\ntrain_df = get_train_df()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_group(train_df):\n    print(\"Grouping users...\") \n    group = train_df[[\"user_id\",\"content_id\",\"answered_correctly\",\"prior_question_elapsed_time\", \"lagtime\",\"part\"]]\\\n                    .groupby(\"user_id\")\\\n                    .apply(lambda r: (r.content_id.values,\n                                      r.answered_correctly.values,\n                                      r.prior_question_elapsed_time.values,\n                                      r.lagtime.values,\n                                      r.part.values))\n    del train_df\n    gc.collect()\n    return group\n\ngroup = get_group(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataloaders(group):\n    print(\"splitting\") \n    train,val = train_test_split(group,test_size=0.2) \n    print(\"train size: \",train.shape,\"validation size: \",val.shape)\n    train_dataset = RiiidDataset(train,max_seq = config.MAX_SEQ)\n    val_dataset = RiiidDataset(val,max_seq = config.MAX_SEQ)\n    train_loader = DataLoader(train_dataset,\n                          batch_size=config.BATCH_SIZE,\n                          num_workers=8,\n                          shuffle=True) \n    val_loader = DataLoader(val_dataset,\n                          batch_size=config.BATCH_SIZE,\n                          num_workers=8,\n                          shuffle=False)\n    del train_dataset,val_dataset \n    gc.collect() \n    return train_loader, val_loader \ntrain_loader, val_loader = get_dataloaders(group) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df, group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(iter(train_loader))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"saint_plus = PlusSAINTModule()\ntrainer = pl.Trainer(gpus=-1,max_epochs=10,progress_bar_refresh_rate=21) \ntrainer.fit(model=saint_plus,\n            train_dataloader=train_loader, \n            val_dataloaders = [val_loader,]) \ntrainer.save_checkpoint(\"model.pt\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}