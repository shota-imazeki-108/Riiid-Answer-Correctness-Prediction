{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_dict = {\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32', \n",
    "    'content_id': 'int16', \n",
    "    'content_type_id':'int8', \n",
    "    'task_container_id': 'int16',\n",
    "    #'user_answer': 'int8',\n",
    "    'answered_correctly': 'int8', \n",
    "    'prior_question_elapsed_time': 'float32', \n",
    "    'prior_question_had_explanation': 'bool'\n",
    "}\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start read train data...\n"
     ]
    }
   ],
   "source": [
    "print('start read train data...')\n",
    "train_df = dt.fread('./input/train.csv', columns=set(data_types_dict.keys())).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101230332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_df = pd.read_pickle('train_df_part.pkl')\n",
    "train_df = pd.concat([train_df, part_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同じ問題(content_id)に取り組んだlagtime\n",
    "train_df['content_lagtime'] = train_df.groupby(['user_id', 'content_id'])['timestamp'].shift()\n",
    "\n",
    "max_timestamp_u_content = train_df[['user_id', 'content_id','timestamp']].groupby(['user_id', 'content_id']).agg(['max']).reset_index()\n",
    "max_timestamp_u_content.columns = ['user_id', 'content_id', 'timestamp']\n",
    "max_timestamp_u_content.user_id=max_timestamp_u_content.user_id.astype('int32')\n",
    "max_timestamp_u_content.to_pickle('max_timestamp_u_content_org.pkl')\n",
    "max_timestamp_u_content=max_timestamp_u_content[max_timestamp_u_content['timestamp'] >43712886024] # timestamp.max(87425772049) / 2\n",
    "# max_timestamp_u_content.to_pickle('max_timestamp_u_content.pkl')\n",
    "del max_timestamp_u_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel/__main__.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "train_df['content_lagtime']=train_df['timestamp']-train_df['content_lagtime']\n",
    "train_df['content_lagtime'].fillna(-1, inplace=True)\n",
    "\n",
    "train_df['content_lagtime']=train_df['content_lagtime']/(1000*3600)\n",
    "train_df.lagtime=train_df.content_lagtime.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1= if the event was the user watching a lecture.\n",
    "cum = train_df.groupby('user_id')['content_type_id'].agg(['cumsum', 'cumcount'])\n",
    "cum['cumcount']=cum['cumcount']+1\n",
    "train_df['user_interaction_count'] = cum['cumcount']\n",
    "# train_df['user_interaction_timestamp_mean'] = train_df['timestamp']/cum['cumcount']\n",
    "# train_df['user_lecture_sum'] = cum['cumsum']\n",
    "# train_df['user_lecture_lv'] = cum['cumsum'] / cum['cumcount']\n",
    "\n",
    "\n",
    "# train_df.user_lecture_lv=train_df.user_lecture_lv.astype('float16')\n",
    "# train_df.user_lecture_sum=train_df.user_lecture_sum.astype('int16')\n",
    "train_df.user_interaction_count=train_df.user_interaction_count.astype('int16')\n",
    "# train_df['user_interaction_timestamp_mean']=train_df['user_interaction_timestamp_mean']/(1000*3600)\n",
    "# train_df.user_interaction_timestamp_mean=train_df.user_interaction_timestamp_mean.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cum\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start handle train_df...\n"
     ]
    }
   ],
   "source": [
    "print('start handle train_df...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lagtime_in_lecture'] = train_df.groupby('user_id')['timestamp'].shift()\n",
    "\n",
    "train_df['lagtime_in_lecture']=train_df['timestamp']-train_df['lagtime_in_lecture']\n",
    "lagtime_in_lecture_mean=train_df['lagtime_in_lecture'].mean()\n",
    "train_df['lagtime_in_lecture'].fillna(lagtime_in_lecture_mean, inplace=True)\n",
    "\n",
    "train_df['lagtime_in_lecture']=train_df['lagtime_in_lecture']/(1000*3600)\n",
    "train_df.lagtime_in_lecture=train_df.lagtime_in_lecture.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add\n",
    "# train_df['lag'] = train_df.groupby(['user_id', 'part'])[target].shift()\n",
    "\n",
    "cum = train_df.groupby(['user_id', 'part'])['content_type_id'].agg(['cumsum', 'cumcount'])\n",
    "##cum['cumcount']=cum['cumcount']+1\n",
    "part_lecture_user_agg = train_df.groupby(['user_id', 'part'])['content_type_id'].agg(['sum', 'count']).astype('int16')\n",
    "part_lecture_user_agg.to_pickle('./intermed/part_lecture_user_agg.pkl')\n",
    "del part_lecture_user_agg\n",
    "\n",
    "cum['cumsum'].fillna(0, inplace=True)\n",
    "train_df['user_lecture_sum'] = cum['cumsum']\n",
    "train_df['user_lecture_lv'] = cum['cumsum'] / cum['cumcount']\n",
    "#train_df['user_answer_count'] = cum['cumcount']\n",
    "\n",
    "# train_df.drop(columns=['lag'], inplace=True)\n",
    "train_df.user_lecture_lv=train_df.user_lecture_lv.astype('float16')\n",
    "train_df.user_lecture_sum=train_df.user_lecture_sum.astype('int16')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "train_df = train_df.astype(data_types_dict)\n",
    "train_df = train_df[train_df[target] != -1].reset_index(drop=True) # lecture削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_explation_agg=train_df[[\"content_id\",\"prior_question_had_explanation\",target]].groupby([\"content_id\",\"prior_question_had_explanation\"])[target].agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_explation_agg=content_explation_agg.unstack()\n",
    "\n",
    "content_explation_agg=content_explation_agg.reset_index()\n",
    "content_explation_agg.columns = ['content_id', 'content_explation_false_mean','content_explation_true_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_explation_agg.content_id=content_explation_agg.content_id.astype('int16')\n",
    "content_explation_agg.content_explation_false_mean=content_explation_agg.content_explation_false_mean.astype('float16')\n",
    "content_explation_agg.content_explation_true_mean=content_explation_agg.content_explation_true_mean.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start handle attempt_no...\n"
     ]
    }
   ],
   "source": [
    "print('start handle attempt_no...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df[\"attempt_no\"] = 1\n",
    "train_df.attempt_no=train_df.attempt_no.astype('int8')\n",
    "#\n",
    "attempt_no_agg=train_df.groupby([\"user_id\",\"content_id\"])[\"attempt_no\"].agg(['sum']).astype('int8')\n",
    "#attempt_no_agg=attempt_no_agg.astype('int8')\n",
    "train_df[\"attempt_no\"] = train_df[[\"user_id\",\"content_id\",'attempt_no']].groupby([\"user_id\",\"content_id\"])[\"attempt_no\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt_no_agg=attempt_no_agg.reset_index()\n",
    "attempt_no_agg=attempt_no_agg[attempt_no_agg['sum'] >1]\n",
    "\n",
    "# attempt_no_agg.to_pickle('attempt_no_agg.pkl')\n",
    "del attempt_no_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum = train_df.groupby('user_id')['attempt_no'].agg(['cumsum', 'cumcount'])\n",
    "##cum['cumcount']=cum['cumcount']+1\n",
    "attempt_cum_agg = train_df.groupby('user_id')['attempt_no'].agg(['sum', 'count']).astype('int16')\n",
    "# attempt_cum_agg.to_pickle('attempt_cum_agg.pkl')\n",
    "del attempt_cum_agg\n",
    "\n",
    "cum['cumsum'].fillna(0, inplace=True)\n",
    "\n",
    "train_df['attempt_no_mean'] = cum['cumsum'] / cum['cumcount']\n",
    "train_df.attempt_no_mean=train_df.attempt_no_mean.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start handle timestamp...\n"
     ]
    }
   ],
   "source": [
    "print('start handle timestamp...')\n",
    "prior_question_elapsed_time_mean=train_df['prior_question_elapsed_time'].mean()\n",
    "train_df['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['lag'] = train_df.groupby('user_id')[target].shift()\n",
    "\n",
    "cum = train_df.groupby('user_id')['lag'].agg(['cumsum', 'cumcount'])\n",
    "##cum['cumcount']=cum['cumcount']+1\n",
    "user_agg = train_df.groupby('user_id')['lag'].agg(['sum', 'count']).astype('int16')\n",
    "cum['cumsum'].fillna(0, inplace=True)\n",
    "\n",
    "train_df['user_correctness'] = cum['cumsum'] / cum['cumcount']\n",
    "train_df['user_cumcount'] = cum['cumcount']\n",
    "train_df['user_correct_count'] = cum['cumsum']\n",
    "train_df['user_uncorrect_count'] = cum['cumcount']-cum['cumsum']\n",
    "#train_df['user_answer_count'] = cum['cumcount']\n",
    "train_df.drop(columns=['lag'], inplace=True)\n",
    "train_df['user_correctness'].fillna(0.67, inplace=True)\n",
    "train_df.user_correctness=train_df.user_correctness.astype('float16')\n",
    "train_df.user_correct_count=train_df.user_correct_count.astype('int16')\n",
    "train_df.user_uncorrect_count=train_df.user_uncorrect_count.astype('int16')\n",
    "#train_df.user_answer_count=train_df.user_answer_count.astype('int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add\n",
    "train_df['lag'] = train_df.groupby(['user_id', 'part'])[target].shift()\n",
    "\n",
    "cum = train_df.groupby(['user_id', 'part'])['lag'].agg(['cumsum', 'cumcount'])\n",
    "##cum['cumcount']=cum['cumcount']+1\n",
    "part_user_agg = train_df.groupby(['user_id', 'part'])['lag'].agg(['sum', 'count']).astype('int16')\n",
    "# part_user_agg.to_pickle('./intermed/part_user_agg.pkl')\n",
    "del part_user_agg\n",
    "\n",
    "cum['cumsum'].fillna(0, inplace=True)\n",
    "\n",
    "train_df['user_part_correctness'] = cum['cumsum'] / cum['cumcount'] # part別正答率\n",
    "# train_df['user_part_rate'] = cum['cumcount'] / train_df['user_cumcount']# part別回答割合\n",
    "#train_df['user_answer_count'] = cum['cumcount']\n",
    "train_df.drop(columns=['lag', 'user_cumcount'], inplace=True)\n",
    "train_df['user_part_correctness'].fillna(0.67, inplace=True)\n",
    "train_df.user_part_correctness=train_df.user_part_correctness.astype('float16')\n",
    "# train_df.user_part_rate=train_df.user_part_rate.astype('float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add\n",
    "# 同じ問partに取り組んだlagtime\n",
    "train_df['part_lagtime'] = train_df.groupby(['user_id', 'part'])['timestamp'].shift()\n",
    "\n",
    "max_timestamp_u_part = train_df[['user_id', 'part','timestamp']].groupby(['user_id', 'part']).agg(['max']).reset_index()\n",
    "max_timestamp_u_part.columns = ['user_id', 'part', 'timestamp']\n",
    "max_timestamp_u_part.user_id=max_timestamp_u_part.user_id.astype('int32')\n",
    "max_timestamp_u_part.to_pickle('max_timestamp_u_part_org.pkl')\n",
    "max_timestamp_u_part=max_timestamp_u_part[max_timestamp_u_part['timestamp'] >43712886024] # timestamp.max(87425772049) / 2\n",
    "# max_timestamp_u_part.to_pickle('max_timestamp_u_part.pkl')\n",
    "del max_timestamp_u_part\n",
    "\n",
    "train_df['part_lagtime']=train_df['timestamp']-train_df['part_lagtime']\n",
    "train_df['part_lagtime'].fillna(-1, inplace=True)\n",
    "\n",
    "train_df['part_lagtime']=train_df['part_lagtime']/(1000*3600)\n",
    "train_df.part_lagtime=train_df.part_lagtime.astype('float32')\n",
    "\n",
    "train_df.drop(columns=['part'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max']).reset_index()\n",
    "max_timestamp_u.columns = ['user_id', 'max_time_stamp']\n",
    "max_timestamp_u.user_id=max_timestamp_u.user_id.astype('int32')\n",
    "# max_timestamp_u.to_pickle('max_timestamp_u.pkl')\n",
    "\n",
    "del max_timestamp_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['lagtime'] = train_df.groupby('user_id')['timestamp'].shift()\n",
    "\n",
    "max_timestamp_u2 = train_df[['user_id','lagtime']].groupby(['user_id']).agg(['max']).reset_index()\n",
    "max_timestamp_u2.columns = ['user_id', 'max_time_stamp2']\n",
    "max_timestamp_u2.user_id=max_timestamp_u2.user_id.astype('int32')\n",
    "\n",
    "# max_timestamp_u2.to_pickle('max_timestamp_u2.pkl')\n",
    "del max_timestamp_u2\n",
    "\n",
    "train_df['lagtime']=train_df['timestamp']-train_df['lagtime']\n",
    "lagtime_mean=train_df['lagtime'].mean()\n",
    "train_df['lagtime'].fillna(lagtime_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lag_elapsed_time'] = train_df['lagtime'] - train_df['prior_question_elapsed_time']\n",
    "\n",
    "lag_elapsed_time_mean=train_df['lag_elapsed_time'].mean()\n",
    "train_df['lag_elapsed_time'].fillna(lag_elapsed_time_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lagtime']=train_df['lagtime']/(1000*3600)\n",
    "train_df.lagtime=train_df.lagtime.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['lagtime2'] = train_df.groupby('user_id')['timestamp'].shift(2)\n",
    "\n",
    "max_timestamp_u3 = train_df[['user_id','lagtime2']].groupby(['user_id']).agg(['max']).reset_index()\n",
    "max_timestamp_u3.columns = ['user_id', 'max_time_stamp3']\n",
    "max_timestamp_u3.user_id=max_timestamp_u3.user_id.astype('int32')\n",
    "\n",
    "# max_timestamp_u3.to_pickle('max_timestamp_u3.pkl')\n",
    "del max_timestamp_u3\n",
    "\n",
    "train_df['lagtime2']=train_df['timestamp']-train_df['lagtime2']\n",
    "lagtime_mean2=train_df['lagtime2'].mean()\n",
    "train_df['lagtime2'].fillna(lagtime_mean2, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lagtime2']=train_df['lagtime2']/(1000*3600)\n",
    "train_df.lagtime2=train_df.lagtime2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df['lagtime3'] = train_df.groupby('user_id')['timestamp'].shift(3)\n",
    "\n",
    "train_df['lagtime3']=train_df['timestamp']-train_df['lagtime3']\n",
    "lagtime_mean3=train_df['lagtime3'].mean()\n",
    "train_df['lagtime3'].fillna(lagtime_mean3, inplace=True)\n",
    "train_df['lagtime3']=train_df['lagtime3']/(1000*3600)\n",
    "train_df.lagtime3=train_df.lagtime3.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lagtime1_2'] = train_df['lagtime'] - train_df['lagtime2']\n",
    "train_df['lagtime2_3'] = train_df['lagtime2'] - train_df['lagtime3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['timestamp']=train_df['timestamp']/(1000*3600)\n",
    "#\n",
    "train_df.timestamp=train_df.timestamp.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prior_question_elapsed_time = train_df[['user_id','prior_question_elapsed_time']].groupby(['user_id']).tail(1)\n",
    "user_prior_question_elapsed_time.columns = ['user_id', 'prior_question_elapsed_time']\n",
    "\n",
    "# user_prior_question_elapsed_time.to_pickle('user_prior_question_elapsed_time.pkl')\n",
    "del user_prior_question_elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cum\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.prior_question_had_explanation=train_df.prior_question_had_explanation.astype('int8')\n",
    "explanation_agg = train_df.groupby('user_id')['prior_question_had_explanation'].agg(['sum', 'count'])\n",
    "explanation_agg=explanation_agg.astype('int16')\n",
    "# explanation_agg.sum=explanation_agg.sum.astype('int16')\n",
    "# explanation_agg.count=explanation_agg.count.astype('int16')\n",
    "#explanation_agg.var=explanation_agg.var.astype('float16')\n",
    "\n",
    "# explanation_agg.to_pickle('explanation_agg.pkl')\n",
    "del explanation_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#train_df['lag'] = train_df.groupby('user_id')['prior_question_had_explanation'].shift()\n",
    "\n",
    "cum = train_df.groupby('user_id')['prior_question_had_explanation'].agg(['cumsum', 'cumcount'])\n",
    "cum['cumcount']=cum['cumcount']+1\n",
    "# train_df['explanation_mean'] = cum['cumsum'] / cum['cumcount']\n",
    "# train_df['explanation_true_count'] = cum['cumsum']\n",
    "train_df['explanation_false_count'] =  cum['cumcount']-cum['cumsum']\n",
    "#train_df.drop(columns=['lag'], inplace=True)\n",
    "\n",
    "# train_df.explanation_mean=train_df.explanation_mean.astype('float16')\n",
    "# train_df.explanation_true_count=train_df.explanation_true_count.astype('int16')\n",
    "train_df.explanation_false_count=train_df.explanation_false_count.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cum\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_agg = train_df.groupby('content_id')[target].agg(['sum', 'count','var'])\n",
    "task_container_agg = train_df.groupby('task_container_id')[target].agg(['sum', 'count','var'])\n",
    "content_agg=content_agg.astype('float32')\n",
    "task_container_agg=task_container_agg.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99271300"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train_df['task_container_uncor_count'] = train_df['task_container_id'].map(task_container_agg['count']-task_container_agg['sum']).astype('int32')\n",
    "# train_df['task_container_cor_count'] = train_df['task_container_id'].map(task_container_agg['sum']).astype('int32')\n",
    "# train_df['task_container_std'] = train_df['task_container_id'].map(task_container_agg['var']).astype('float16')\n",
    "# train_df['task_container_correctness'] = train_df['task_container_id'].map(task_container_agg['sum'] / task_container_agg['count'])\n",
    "# train_df.task_container_correctness=train_df.task_container_correctness.astype('float16')\n",
    "\n",
    "# task_container_agg.to_pickle('task_container_agg.pkl')\n",
    "del task_container_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_elapsed_time_agg=train_df.groupby('content_id')['prior_question_elapsed_time'].agg(['mean'])\n",
    "content_had_explanation_agg=train_df.groupby('content_id')['prior_question_had_explanation'].agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>content_lagtime</th>\n",
       "      <th>user_interaction_count</th>\n",
       "      <th>...</th>\n",
       "      <th>user_part_correctness</th>\n",
       "      <th>part_lagtime</th>\n",
       "      <th>lagtime</th>\n",
       "      <th>lag_elapsed_time</th>\n",
       "      <th>lagtime2</th>\n",
       "      <th>lagtime3</th>\n",
       "      <th>lagtime1_2</th>\n",
       "      <th>lagtime2_3</th>\n",
       "      <th>explanation_false_count</th>\n",
       "      <th>task_container_uncor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13005.081055</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>5.678317</td>\n",
       "      <td>2.042894e+07</td>\n",
       "      <td>11.214070</td>\n",
       "      <td>16.669001</td>\n",
       "      <td>-5.535753</td>\n",
       "      <td>-5.454930</td>\n",
       "      <td>1</td>\n",
       "      <td>187175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015823</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581750e-02</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>1.994300e+04</td>\n",
       "      <td>11.214070</td>\n",
       "      <td>16.669001</td>\n",
       "      <td>-11.198253</td>\n",
       "      <td>-5.454930</td>\n",
       "      <td>2</td>\n",
       "      <td>223198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032867</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>6.420000e+03</td>\n",
       "      <td>0.032879</td>\n",
       "      <td>16.669001</td>\n",
       "      <td>-0.015818</td>\n",
       "      <td>-16.636122</td>\n",
       "      <td>3</td>\n",
       "      <td>126682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036438</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.556667e-03</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>-6.196000e+03</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>-0.015817</td>\n",
       "      <td>4</td>\n",
       "      <td>180574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038330</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.777778e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.888333e-03</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>-4.202000e+03</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>-0.003557</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>5</td>\n",
       "      <td>361957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0   0.000000      115        5692                0                  1   \n",
       "1   0.015823      115        5716                0                  2   \n",
       "2   0.032867      115         128                0                  0   \n",
       "3   0.036438      115        7860                0                  3   \n",
       "4   0.038330      115        7922                0                  4   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                 13005.081055   \n",
       "1                   1                 37000.000000   \n",
       "2                   1                 55000.000000   \n",
       "3                   1                 19000.000000   \n",
       "4                   1                 11000.000000   \n",
       "\n",
       "   prior_question_had_explanation  content_lagtime  user_interaction_count  \\\n",
       "0                               0    -2.777778e-07                       1   \n",
       "1                               0    -2.777778e-07                       2   \n",
       "2                               0    -2.777778e-07                       3   \n",
       "3                               0    -2.777778e-07                       4   \n",
       "4                               0    -2.777778e-07                       5   \n",
       "\n",
       "   ...  user_part_correctness  part_lagtime   lagtime  lag_elapsed_time  \\\n",
       "0  ...               0.669922 -2.777778e-07  5.678317      2.042894e+07   \n",
       "1  ...               1.000000  1.581750e-02  0.015818      1.994300e+04   \n",
       "2  ...               0.669922 -2.777778e-07  0.017061      6.420000e+03   \n",
       "3  ...               1.000000  3.556667e-03  0.003557     -6.196000e+03   \n",
       "4  ...               1.000000  1.888333e-03  0.001888     -4.202000e+03   \n",
       "\n",
       "    lagtime2   lagtime3  lagtime1_2  lagtime2_3  explanation_false_count  \\\n",
       "0  11.214070  16.669001   -5.535753   -5.454930                        1   \n",
       "1  11.214070  16.669001  -11.198253   -5.454930                        2   \n",
       "2   0.032879  16.669001   -0.015818  -16.636122                        3   \n",
       "3   0.020618   0.036435   -0.017061   -0.015817                        4   \n",
       "4   0.005445   0.022506   -0.003557   -0.017061                        5   \n",
       "\n",
       "   task_container_uncor_count  \n",
       "0                      187175  \n",
       "1                      223198  \n",
       "2                      126682  \n",
       "3                      180574  \n",
       "4                      361957  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start questions data...\n"
     ]
    }
   ],
   "source": [
    "print('start questions data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\n",
    "    './input/questions.csv', \n",
    "    usecols=[0, 1,3,4],\n",
    "    dtype={'question_id': 'int16','bundle_id': 'int16', 'part': 'int8','tags': 'str'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_agg = questions_df.groupby('bundle_id')['question_id'].agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['content_sub_bundle'] = questions_df['bundle_id'].map(bundle_agg['count']).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions_df['tags'].fillna('188', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettags(tags,num):\n",
    "    tags_splits=tags.split(\" \")\n",
    "    result='' \n",
    "    for t in tags_splits:\n",
    "        x=int(t)\n",
    "        if(x<32*(num+1) and x>=32*num):#num \n",
    "            result=result+' '+t\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for num in range(0,6):\n",
    "    questions_df[\"tags\"+str(num)] = questions_df[\"tags\"].apply(lambda row: gettags(row,num))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.unique(questions_df['tags'+str(num)].values))\n",
    "    #questions_df[['tags'+str(num)]=\n",
    "    questions_df['tags'+str(num)]=questions_df[['tags'+str(num)]].apply(le.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df_dict = {   \n",
    "    'tags0': 'int8',\n",
    "    'tags1': 'int8',\n",
    "    'tags2': 'int8',\n",
    "    'tags3': 'int8',\n",
    "    'tags4': 'int8',\n",
    "    'tags5': 'int8',\n",
    "    #'tags6': 'int8',\n",
    "    #'tags7': 'int8'\n",
    "}\n",
    "questions_df = questions_df.astype(questions_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.drop(columns=['tags'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions_df['part_bundle_id']=questions_df['part']*100000+questions_df['bundle_id']\n",
    "questions_df.part_bundle_id=questions_df.part_bundle_id.astype('int32')\n",
    "# tag = questions_df[\"tags\"].str.split(\" \", n = 10, expand = True)\n",
    "# tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "# #\n",
    "\n",
    "# tag.fillna(0, inplace=True)\n",
    "# tag = tag.astype('int16')\n",
    "# questions_df =  pd.concat([questions_df,tag],axis=1).drop(['tags'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.rename(columns={'question_id':'content_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.merge(questions_df, content_explation_agg, on='content_id', how='left',right_index=True)#\n",
    "# questions_df.content_explation_false_mean=questions_df.content_explation_false_mean.astype('float16')\n",
    "# questions_df.content_explation_true_mean=questions_df.content_explation_true_mean.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del content_explation_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['sum'] = questions_df['content_id'].map(content_agg['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['content_correctness'] = questions_df['content_id'].map(content_agg['sum'] / content_agg['count'])\n",
    "questions_df.content_correctness=questions_df.content_correctness.astype('float16')\n",
    "questions_df['content_correctness_std'] = questions_df['content_id'].map(content_agg['var'])\n",
    "questions_df.content_correctness_std=questions_df.content_correctness_std.astype('float16')\n",
    "questions_df['content_uncorrect_count'] = questions_df['content_id'].map(content_agg['count']-content_agg['sum']).astype('int32')\n",
    "questions_df['content_correct_count'] = questions_df['content_id'].map(content_agg['sum']).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['content_elapsed_time_mean'] = questions_df['content_id'].map(content_elapsed_time_agg['mean'])\n",
    "questions_df.content_elapsed_time_mean=questions_df.content_elapsed_time_mean.astype('float16')\n",
    "questions_df['content_had_explanation_mean'] = questions_df['content_id'].map(content_had_explanation_agg['mean'])\n",
    "questions_df.content_had_explanation_mean=questions_df.content_had_explanation_mean.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del content_elapsed_time_agg\n",
    "del content_had_explanation_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_agg = questions_df.groupby('part')['content_correctness'].agg(['mean', 'var'])\n",
    "questions_df['part_correctness_mean'] = questions_df['part'].map(part_agg['mean'])\n",
    "questions_df['part_correctness_std'] = questions_df['part'].map(part_agg['var'])\n",
    "questions_df.part_correctness_mean=questions_df.part_correctness_mean.astype('float16')\n",
    "questions_df.part_correctness_std=questions_df.part_correctness_std.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_agg = questions_df.groupby('part')['content_uncorrect_count'].agg(['sum'])\n",
    "questions_df['part_uncor_count'] = questions_df['part'].map(part_agg['sum']).astype('int32')\n",
    "#\n",
    "part_agg = questions_df.groupby('part')['content_correct_count'].agg(['sum'])\n",
    "questions_df['part_cor_count'] = questions_df['part'].map(part_agg['sum']).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_agg = questions_df.groupby('bundle_id')['content_correctness'].agg(['mean'])\n",
    "questions_df['bundle_correctness_mean'] = questions_df['bundle_id'].map(bundle_agg['mean'])\n",
    "questions_df.bundle_correctness_mean=questions_df.bundle_correctness_mean.astype('float16')\n",
    "\n",
    "# bundle_agg = questions_df.groupby('bundle_id')['content_uncorrect_count'].agg(['sum'])\n",
    "# questions_df['bundle_uncor_count'] = questions_df['bundle_id'].map(bundle_agg['sum']).astype('int32')\n",
    "# #\n",
    "# bundle_agg = questions_df.groupby('bundle_id')['content_correct_count'].agg(['sum'])\n",
    "# questions_df['bundle_cor_count'] = questions_df['bundle_id'].map(bundle_agg['sum']).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del content_agg\n",
    "del bundle_agg\n",
    "del part_agg\n",
    "#del tags1_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin\n",
    "features_dict = {\n",
    "    #'user_id',\n",
    "    'timestamp':'float16',#\n",
    "    'user_interaction_count':'int16',\n",
    "    'user_interaction_timestamp_mean':'float32',\n",
    "    'lagtime':'float32',#\n",
    "    'lagtime2':'float32',\n",
    "    'lagtime3':'float32',\n",
    "    #'lagtime_mean':'int32',\n",
    "    'content_id':'int16',\n",
    "    'task_container_id':'int16',\n",
    "    'user_lecture_sum':'int16',#\n",
    "    'user_lecture_lv':'float16',##\n",
    "    'prior_question_elapsed_time':'float32',#\n",
    "    'delta_prior_question_elapsed_time':'int32',#\n",
    "    'user_correctness':'float16',#\n",
    "    'user_uncorrect_count':'int16',#\n",
    "    'user_correct_count':'int16',#\n",
    "    #'content_correctness':'float16',\n",
    "    'content_correctness_std':'float16',\n",
    "    'content_correct_count':'int32',\n",
    "    'content_uncorrect_count':'int32',#\n",
    "    'content_elapsed_time_mean':'float16',\n",
    "    'content_had_explanation_mean':'float16',\n",
    "    'content_explation_false_mean':'float16',\n",
    "    'content_explation_true_mean':'float16',\n",
    "    'task_container_correctness':'float16',\n",
    "    'task_container_std':'float16',\n",
    "    'task_container_cor_count':'int32',#\n",
    "    'task_container_uncor_count':'int32',#\n",
    "    'attempt_no':'int8',#\n",
    "    'part':'int8',\n",
    "    'part_correctness_mean':'float16',\n",
    "    'part_correctness_std':'float16',\n",
    "    'part_uncor_count':'int32',\n",
    "    'part_cor_count':'int32',\n",
    "    'tags0': 'int8',\n",
    "    'tags1': 'int8',\n",
    "    'tags2': 'int8',\n",
    "    'tags3': 'int8',\n",
    "    'tags4': 'int8',\n",
    "    'tags5': 'int8',\n",
    "   # 'tags6': 'int8',\n",
    "   # 'tags7': 'int8',\n",
    "#     'tags0_correctness_mean':'float16',\n",
    "#     'tags1_correctness_mean':'float16',\n",
    "#     'tags2_correctness_mean':'float16',\n",
    "#     'tags4_correctness_mean':'float16',\n",
    "#     'bundle_id':'int16',\n",
    "#     'bundle_correctness_mean':'float16',\n",
    "#     'bundle_uncor_count':'int32',\n",
    "#     'bundle_cor_count':'int32',\n",
    "    'part_bundle_id':'int32',\n",
    "    'content_sub_bundle':'int8',\n",
    "    'prior_question_had_explanation':'int8',\n",
    "    'explanation_mean':'float16', #\n",
    "    #'explanation_var',#\n",
    "    'explanation_false_count':'int16',#\n",
    "    'explanation_true_count':'int16',#\n",
    "   # 'community':'int8',\n",
    "#     'part_1',\n",
    "#     'part_2',\n",
    "#     'part_3',\n",
    "#     'part_4',\n",
    "#     'part_5',\n",
    "#     'part_6',\n",
    "#     'part_7',\n",
    "#     'type_of_concept',\n",
    "#     'type_of_intention',\n",
    "#     'type_of_solving_question',\n",
    "#     'type_of_starter'\n",
    "}\n",
    "categorical_columns= [\n",
    "    #'user_id',\n",
    "    'content_id',\n",
    "    'task_container_id',\n",
    "    'part',\n",
    "   # 'community',\n",
    "    'tags0',\n",
    "    'tags1',\n",
    "    'tags2',\n",
    "    'tags3',\n",
    "    'tags4',\n",
    "    'tags5',\n",
    "    #'tags6',\n",
    "    #'tags7',\n",
    "    #'bundle_id',\n",
    "    'part_bundle_id',\n",
    "    'content_sub_bundle',\n",
    "    'prior_question_had_explanation', \n",
    "#     'part_1',\n",
    "#     'part_2',\n",
    "#     'part_3',\n",
    "#     'part_4',\n",
    "#     'part_5',\n",
    "#     'part_6',\n",
    "#     'part_7',\n",
    "#     'type_of_concept',\n",
    "#     'type_of_intention',\n",
    "#     'type_of_solving_question',\n",
    "#     'type_of_starter'\n",
    "]\n",
    "\n",
    "features=list(features_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part_bundle_id', 'content_id']\n"
     ]
    }
   ],
   "source": [
    "###### Value>100000\n",
    "features_dict = {\n",
    "#  'lagtime': 'float32', # curr\n",
    " 'lagtime2': 'float32', #\n",
    " 'lagtime3': 'float32',\n",
    " 'content_id': 'int16',\n",
    "#  'task_container_id': 'int16', # curr\n",
    " 'prior_question_elapsed_time': 'float32',\n",
    " 'user_correctness': 'float16',\n",
    "#  'user_uncorrect_count': 'int16', # curr\n",
    " 'user_correct_count': 'int16',\n",
    " 'content_correctness_std': 'float16',\n",
    " 'content_correct_count': 'int32',\n",
    " 'content_uncorrect_count': 'int32',\n",
    " 'content_had_explanation_mean': 'float16', #\n",
    "#  'content_explation_false_mean': 'float16', # curr\n",
    " 'content_explation_true_mean': 'float16',\n",
    " 'attempt_no': 'int8',\n",
    "#  'part': 'int8', # curr\n",
    " 'part_correctness_mean': 'float16',\n",
    " 'part_bundle_id': 'int32',\n",
    " 'explanation_false_count': 'int16',\n",
    " 'lagtime_in_lecture': 'float32',\n",
    " 'content_lagtime': 'float32',\n",
    "#  'lag_elapsed_time': 'float32', # curr\n",
    " 'attempt_no_mean': 'float16',\n",
    " 'lagtime1_2': 'float32',\n",
    " 'lagtime2_3': 'float32',\n",
    " 'user_part_correctness': 'float16',\n",
    "#  'user_part_rate': 'float16',\n",
    " 'part_lagtime': 'float16',\n",
    " 'user_lecture_sum': 'float16',\n",
    " 'user_lecture_lv': 'int16',\n",
    "#  'community': 'int16',\n",
    "#  'community_correctness_mean': 'float16',\n",
    "#  'lecture_of_day': 'int16',\n",
    "#  'user_interaction_lagtime_mean': 'float32',\n",
    "#  'lagtime_cumsum': 'int16'\n",
    "}\n",
    "\n",
    "features=list(features_dict.keys())\n",
    "\n",
    "delete_col = set(categorical_columns) - set(features)\n",
    "categorical_columns = list(set(categorical_columns) - delete_col)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample end\n",
      "pd.merge(train_df_clf, questions_df)\n",
      "valid_df\n",
      "train_df_clf length： 81973662\n",
      "valid_df length： 17297638\n"
     ]
    }
   ],
   "source": [
    "flag_lgbm=True\n",
    "clfs = list()\n",
    "params = {\n",
    "'num_leaves': 300,\n",
    "'max_bin':450,\n",
    "# 'min_child_weight': 0.03454472573214212,\n",
    "'feature_fraction': 0.52,\n",
    "'bagging_fraction': 0.52,\n",
    "#'min_data_in_leaf': 106,\n",
    "# 'max_depth': -1,\n",
    "'objective': 'binary',\n",
    "'learning_rate': 0.05,\n",
    "\"boosting_type\": \"gbdt\",\n",
    "\"metric\": 'auc',\n",
    "# \"bagging_seed\": 11,\n",
    "# \"verbosity\": -1,\n",
    "# 'reg_alpha': 0.3899927210061127,\n",
    "# 'reg_lambda': 0.6485237330340494,\n",
    "# 'random_state': 47\n",
    "}\n",
    "trains=list()\n",
    "valids=list()\n",
    "num=1\n",
    "for i in range(0,num):\n",
    "    \n",
    "    #train_df=train_df.reset_index(drop=True)\n",
    "    #train_df_clf=train_df.sample(n=1200*10000)\n",
    "    if DEBUG:\n",
    "        train_df_clf=train_df[:10000]\n",
    "    else:\n",
    "#         train_df_clf=train_df[1200*10000:int(2.5*1200)*10000]\n",
    "        train_df_clf=train_df.copy()\n",
    "    \n",
    "    print('sample end')\n",
    "    #train_df.drop(train_df_clf.index, inplace=True)\n",
    "    #print('train_df drop end')\n",
    "    \n",
    "   \n",
    "    del train_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    users=train_df_clf['user_id'].drop_duplicates()#\n",
    "    #\n",
    "    users=users.sample(frac=0.08)\n",
    "    users_df=pd.DataFrame()\n",
    "    users_df['user_id']=users.values\n",
    "   \n",
    "   \n",
    "    valid_df_newuser = pd.merge(train_df_clf, users_df, on=['user_id'], how='inner',right_index=True)\n",
    "    del users_df\n",
    "    del users\n",
    "    gc.collect()\n",
    "    #\n",
    "    train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
    "    print('pd.merge(train_df_clf, questions_df)')\n",
    "    #-----------\n",
    "    #train_df_clf=train_df_clf.sample(frac=0.2)\n",
    "    #train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
    "    train_df_clf = pd.merge(train_df_clf, questions_df, on='content_id', how='left',right_index=True)#\n",
    "    valid_df_newuser = pd.merge(valid_df_newuser, questions_df, on='content_id', how='left',right_index=True)#\n",
    "    del questions_df\n",
    "#     train_df_clf = pd.merge(train_df_clf, user_lecture_stats_part, on='user_id', how=\"left\",right_index=True)\n",
    "#     valid_df_newuser = pd.merge(valid_df_newuser, user_lecture_stats_part, on='user_id', how=\"left\",right_index=True)\n",
    "    print('valid_df')\n",
    "    valid_df=train_df_clf.sample(frac=0.1)\n",
    "    train_df_clf.drop(valid_df.index, inplace=True)\n",
    "    \n",
    "#     test_df=train_df_clf.sample(n=100*10000)\n",
    "#     train_df_clf.drop(test_df.index, inplace=True)\n",
    "   \n",
    "    valid_df = valid_df.append(valid_df_newuser)\n",
    "    del valid_df_newuser\n",
    "    gc.collect()\n",
    "    #\n",
    "\n",
    "    trains.append(train_df_clf)\n",
    "    valids.append(valid_df)\n",
    "    print('train_df_clf length：',len(train_df_clf))\n",
    "    print('valid_df length：',len(valid_df))\n",
    "    #train_df=train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del train_df\n",
    "del train_df_clf\n",
    "del valid_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/lightgbm/basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['content_id', 'part_bundle_id']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 53868920, number of negative: 28104742\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.479528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27265\n",
      "[LightGBM] [Info] Number of data points in the train set: 81973662, number of used features: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.657149 -> initscore=0.650615\n",
      "[LightGBM] [Info] Start training from score 0.650615\n",
      "[1]\ttraining's auc: 0.746369\tvalid_1's auc: 0.746076\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's auc: 0.758096\tvalid_1's auc: 0.757849\n",
      "[3]\ttraining's auc: 0.759978\tvalid_1's auc: 0.759694\n",
      "[4]\ttraining's auc: 0.763564\tvalid_1's auc: 0.763317\n",
      "[5]\ttraining's auc: 0.76443\tvalid_1's auc: 0.764116\n",
      "[6]\ttraining's auc: 0.765079\tvalid_1's auc: 0.764797\n",
      "[7]\ttraining's auc: 0.764628\tvalid_1's auc: 0.764381\n",
      "[8]\ttraining's auc: 0.766154\tvalid_1's auc: 0.765926\n",
      "[9]\ttraining's auc: 0.76715\tvalid_1's auc: 0.766914\n",
      "[10]\ttraining's auc: 0.767965\tvalid_1's auc: 0.767738\n",
      "[11]\ttraining's auc: 0.768231\tvalid_1's auc: 0.767999\n",
      "[12]\ttraining's auc: 0.768994\tvalid_1's auc: 0.768744\n",
      "[13]\ttraining's auc: 0.768926\tvalid_1's auc: 0.768659\n",
      "[14]\ttraining's auc: 0.769596\tvalid_1's auc: 0.769339\n",
      "[15]\ttraining's auc: 0.769683\tvalid_1's auc: 0.769432\n",
      "[16]\ttraining's auc: 0.769833\tvalid_1's auc: 0.769584\n",
      "[17]\ttraining's auc: 0.770348\tvalid_1's auc: 0.770093\n",
      "[18]\ttraining's auc: 0.770726\tvalid_1's auc: 0.770461\n",
      "[19]\ttraining's auc: 0.77098\tvalid_1's auc: 0.77069\n",
      "[20]\ttraining's auc: 0.771116\tvalid_1's auc: 0.77081\n",
      "[21]\ttraining's auc: 0.77115\tvalid_1's auc: 0.770827\n",
      "[22]\ttraining's auc: 0.771103\tvalid_1's auc: 0.770784\n",
      "[23]\ttraining's auc: 0.771363\tvalid_1's auc: 0.771039\n",
      "[24]\ttraining's auc: 0.771729\tvalid_1's auc: 0.771399\n",
      "[25]\ttraining's auc: 0.771908\tvalid_1's auc: 0.771581\n",
      "[26]\ttraining's auc: 0.771964\tvalid_1's auc: 0.771618\n",
      "[27]\ttraining's auc: 0.772197\tvalid_1's auc: 0.771832\n",
      "[28]\ttraining's auc: 0.772419\tvalid_1's auc: 0.77204\n",
      "[29]\ttraining's auc: 0.773022\tvalid_1's auc: 0.772641\n",
      "[30]\ttraining's auc: 0.773466\tvalid_1's auc: 0.773079\n",
      "[31]\ttraining's auc: 0.773702\tvalid_1's auc: 0.773302\n",
      "[32]\ttraining's auc: 0.773812\tvalid_1's auc: 0.773398\n",
      "[33]\ttraining's auc: 0.773914\tvalid_1's auc: 0.773491\n",
      "[34]\ttraining's auc: 0.773959\tvalid_1's auc: 0.773522\n",
      "[35]\ttraining's auc: 0.774075\tvalid_1's auc: 0.773643\n",
      "[36]\ttraining's auc: 0.774115\tvalid_1's auc: 0.773667\n",
      "[37]\ttraining's auc: 0.774245\tvalid_1's auc: 0.77379\n",
      "[38]\ttraining's auc: 0.774283\tvalid_1's auc: 0.773816\n",
      "[39]\ttraining's auc: 0.774396\tvalid_1's auc: 0.773907\n",
      "[40]\ttraining's auc: 0.77468\tvalid_1's auc: 0.774181\n",
      "[41]\ttraining's auc: 0.774812\tvalid_1's auc: 0.774302\n",
      "[42]\ttraining's auc: 0.774975\tvalid_1's auc: 0.774459\n",
      "[43]\ttraining's auc: 0.775168\tvalid_1's auc: 0.77464\n",
      "[44]\ttraining's auc: 0.775272\tvalid_1's auc: 0.774734\n",
      "[45]\ttraining's auc: 0.775435\tvalid_1's auc: 0.774891\n",
      "[46]\ttraining's auc: 0.775531\tvalid_1's auc: 0.774978\n",
      "[47]\ttraining's auc: 0.775707\tvalid_1's auc: 0.77515\n",
      "[48]\ttraining's auc: 0.775759\tvalid_1's auc: 0.775205\n",
      "[49]\ttraining's auc: 0.775953\tvalid_1's auc: 0.775388\n",
      "[50]\ttraining's auc: 0.776093\tvalid_1's auc: 0.775516\n",
      "[51]\ttraining's auc: 0.776196\tvalid_1's auc: 0.775616\n",
      "[52]\ttraining's auc: 0.776303\tvalid_1's auc: 0.775716\n",
      "[53]\ttraining's auc: 0.776457\tvalid_1's auc: 0.775856\n",
      "[54]\ttraining's auc: 0.776619\tvalid_1's auc: 0.77602\n",
      "[55]\ttraining's auc: 0.776769\tvalid_1's auc: 0.776174\n",
      "[56]\ttraining's auc: 0.776997\tvalid_1's auc: 0.776392\n",
      "[57]\ttraining's auc: 0.777047\tvalid_1's auc: 0.776445\n",
      "[58]\ttraining's auc: 0.77717\tvalid_1's auc: 0.776571\n",
      "[59]\ttraining's auc: 0.777226\tvalid_1's auc: 0.77663\n",
      "[60]\ttraining's auc: 0.777497\tvalid_1's auc: 0.77689\n",
      "[61]\ttraining's auc: 0.77756\tvalid_1's auc: 0.776957\n",
      "[62]\ttraining's auc: 0.777674\tvalid_1's auc: 0.777056\n",
      "[63]\ttraining's auc: 0.777772\tvalid_1's auc: 0.777157\n",
      "[64]\ttraining's auc: 0.777906\tvalid_1's auc: 0.777274\n",
      "[65]\ttraining's auc: 0.778034\tvalid_1's auc: 0.7774\n",
      "[66]\ttraining's auc: 0.778122\tvalid_1's auc: 0.777489\n",
      "[67]\ttraining's auc: 0.778238\tvalid_1's auc: 0.777606\n",
      "[68]\ttraining's auc: 0.77836\tvalid_1's auc: 0.777712\n",
      "[69]\ttraining's auc: 0.778441\tvalid_1's auc: 0.777774\n",
      "[70]\ttraining's auc: 0.778556\tvalid_1's auc: 0.777874\n",
      "[71]\ttraining's auc: 0.778676\tvalid_1's auc: 0.777981\n",
      "[72]\ttraining's auc: 0.77879\tvalid_1's auc: 0.778077\n",
      "[73]\ttraining's auc: 0.778909\tvalid_1's auc: 0.778186\n",
      "[74]\ttraining's auc: 0.77896\tvalid_1's auc: 0.778239\n",
      "[75]\ttraining's auc: 0.779077\tvalid_1's auc: 0.778343\n",
      "[76]\ttraining's auc: 0.779225\tvalid_1's auc: 0.778477\n",
      "[77]\ttraining's auc: 0.779326\tvalid_1's auc: 0.778564\n",
      "[78]\ttraining's auc: 0.779367\tvalid_1's auc: 0.778603\n",
      "[79]\ttraining's auc: 0.779529\tvalid_1's auc: 0.778752\n",
      "[80]\ttraining's auc: 0.779603\tvalid_1's auc: 0.778826\n",
      "[81]\ttraining's auc: 0.779722\tvalid_1's auc: 0.77893\n",
      "[82]\ttraining's auc: 0.779851\tvalid_1's auc: 0.779046\n",
      "[83]\ttraining's auc: 0.779966\tvalid_1's auc: 0.779144\n",
      "[84]\ttraining's auc: 0.780082\tvalid_1's auc: 0.779262\n",
      "[85]\ttraining's auc: 0.780214\tvalid_1's auc: 0.779383\n",
      "[86]\ttraining's auc: 0.780265\tvalid_1's auc: 0.779435\n",
      "[87]\ttraining's auc: 0.780357\tvalid_1's auc: 0.779514\n",
      "[88]\ttraining's auc: 0.78045\tvalid_1's auc: 0.779589\n",
      "[89]\ttraining's auc: 0.780556\tvalid_1's auc: 0.779678\n",
      "[90]\ttraining's auc: 0.780643\tvalid_1's auc: 0.779749\n",
      "[91]\ttraining's auc: 0.780729\tvalid_1's auc: 0.779822\n",
      "[92]\ttraining's auc: 0.780853\tvalid_1's auc: 0.779945\n",
      "[93]\ttraining's auc: 0.780957\tvalid_1's auc: 0.780035\n",
      "[94]\ttraining's auc: 0.781\tvalid_1's auc: 0.780079\n",
      "[95]\ttraining's auc: 0.781093\tvalid_1's auc: 0.780154\n",
      "[96]\ttraining's auc: 0.781145\tvalid_1's auc: 0.780208\n",
      "[97]\ttraining's auc: 0.781224\tvalid_1's auc: 0.780268\n",
      "[98]\ttraining's auc: 0.781291\tvalid_1's auc: 0.780319\n",
      "[99]\ttraining's auc: 0.781365\tvalid_1's auc: 0.780375\n",
      "[100]\ttraining's auc: 0.781449\tvalid_1's auc: 0.780445\n",
      "[101]\ttraining's auc: 0.781534\tvalid_1's auc: 0.780511\n",
      "[102]\ttraining's auc: 0.781584\tvalid_1's auc: 0.780561\n",
      "[103]\ttraining's auc: 0.781671\tvalid_1's auc: 0.780625\n",
      "[104]\ttraining's auc: 0.781746\tvalid_1's auc: 0.78068\n",
      "[105]\ttraining's auc: 0.781826\tvalid_1's auc: 0.780738\n",
      "[106]\ttraining's auc: 0.781897\tvalid_1's auc: 0.780793\n",
      "[107]\ttraining's auc: 0.781991\tvalid_1's auc: 0.780871\n",
      "[108]\ttraining's auc: 0.782039\tvalid_1's auc: 0.78092\n",
      "[109]\ttraining's auc: 0.782111\tvalid_1's auc: 0.780979\n",
      "[110]\ttraining's auc: 0.782174\tvalid_1's auc: 0.781041\n",
      "[111]\ttraining's auc: 0.78226\tvalid_1's auc: 0.78111\n",
      "[112]\ttraining's auc: 0.782344\tvalid_1's auc: 0.78118\n",
      "[113]\ttraining's auc: 0.782405\tvalid_1's auc: 0.781218\n",
      "[114]\ttraining's auc: 0.782449\tvalid_1's auc: 0.781259\n",
      "[115]\ttraining's auc: 0.782528\tvalid_1's auc: 0.781317\n",
      "[116]\ttraining's auc: 0.78259\tvalid_1's auc: 0.78136\n",
      "[117]\ttraining's auc: 0.782683\tvalid_1's auc: 0.781433\n",
      "[118]\ttraining's auc: 0.782777\tvalid_1's auc: 0.78151\n",
      "[119]\ttraining's auc: 0.782835\tvalid_1's auc: 0.781552\n",
      "[120]\ttraining's auc: 0.782875\tvalid_1's auc: 0.781592\n",
      "[121]\ttraining's auc: 0.782955\tvalid_1's auc: 0.781656\n",
      "[122]\ttraining's auc: 0.783035\tvalid_1's auc: 0.781715\n",
      "[123]\ttraining's auc: 0.783099\tvalid_1's auc: 0.781758\n",
      "[124]\ttraining's auc: 0.783169\tvalid_1's auc: 0.781809\n",
      "[125]\ttraining's auc: 0.783242\tvalid_1's auc: 0.781862\n",
      "[126]\ttraining's auc: 0.783303\tvalid_1's auc: 0.781904\n",
      "[127]\ttraining's auc: 0.783358\tvalid_1's auc: 0.781944\n",
      "[128]\ttraining's auc: 0.783421\tvalid_1's auc: 0.782006\n",
      "[129]\ttraining's auc: 0.783474\tvalid_1's auc: 0.782058\n",
      "[130]\ttraining's auc: 0.783532\tvalid_1's auc: 0.782096\n",
      "[131]\ttraining's auc: 0.783602\tvalid_1's auc: 0.782145\n",
      "[132]\ttraining's auc: 0.783659\tvalid_1's auc: 0.782178\n",
      "[133]\ttraining's auc: 0.783732\tvalid_1's auc: 0.782224\n",
      "[134]\ttraining's auc: 0.783792\tvalid_1's auc: 0.782261\n",
      "[135]\ttraining's auc: 0.783853\tvalid_1's auc: 0.782305\n",
      "[136]\ttraining's auc: 0.78394\tvalid_1's auc: 0.782371\n",
      "[137]\ttraining's auc: 0.783966\tvalid_1's auc: 0.782397\n",
      "[138]\ttraining's auc: 0.784008\tvalid_1's auc: 0.78242\n",
      "[139]\ttraining's auc: 0.784086\tvalid_1's auc: 0.782481\n",
      "[140]\ttraining's auc: 0.784149\tvalid_1's auc: 0.782523\n",
      "[141]\ttraining's auc: 0.784214\tvalid_1's auc: 0.782564\n",
      "[142]\ttraining's auc: 0.784281\tvalid_1's auc: 0.78261\n",
      "[143]\ttraining's auc: 0.784336\tvalid_1's auc: 0.782642\n",
      "[144]\ttraining's auc: 0.784385\tvalid_1's auc: 0.782671\n",
      "[145]\ttraining's auc: 0.784445\tvalid_1's auc: 0.782714\n",
      "[146]\ttraining's auc: 0.784502\tvalid_1's auc: 0.782751\n",
      "[147]\ttraining's auc: 0.784557\tvalid_1's auc: 0.782782\n",
      "[148]\ttraining's auc: 0.784629\tvalid_1's auc: 0.782838\n",
      "[149]\ttraining's auc: 0.784664\tvalid_1's auc: 0.782874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttraining's auc: 0.784739\tvalid_1's auc: 0.78293\n",
      "[151]\ttraining's auc: 0.7848\tvalid_1's auc: 0.782972\n",
      "[152]\ttraining's auc: 0.784852\tvalid_1's auc: 0.783024\n",
      "[153]\ttraining's auc: 0.784899\tvalid_1's auc: 0.78305\n",
      "[154]\ttraining's auc: 0.784927\tvalid_1's auc: 0.783076\n",
      "[155]\ttraining's auc: 0.784983\tvalid_1's auc: 0.783112\n",
      "[156]\ttraining's auc: 0.785047\tvalid_1's auc: 0.783153\n",
      "[157]\ttraining's auc: 0.785097\tvalid_1's auc: 0.78318\n",
      "[158]\ttraining's auc: 0.785172\tvalid_1's auc: 0.783238\n",
      "[159]\ttraining's auc: 0.785224\tvalid_1's auc: 0.783273\n",
      "[160]\ttraining's auc: 0.785253\tvalid_1's auc: 0.783302\n",
      "[161]\ttraining's auc: 0.78531\tvalid_1's auc: 0.783336\n",
      "[162]\ttraining's auc: 0.78536\tvalid_1's auc: 0.783373\n",
      "[163]\ttraining's auc: 0.785412\tvalid_1's auc: 0.7834\n",
      "[164]\ttraining's auc: 0.785467\tvalid_1's auc: 0.78343\n",
      "[165]\ttraining's auc: 0.785498\tvalid_1's auc: 0.783461\n",
      "[166]\ttraining's auc: 0.78557\tvalid_1's auc: 0.78351\n",
      "[167]\ttraining's auc: 0.785626\tvalid_1's auc: 0.783551\n",
      "[168]\ttraining's auc: 0.785682\tvalid_1's auc: 0.783587\n",
      "[169]\ttraining's auc: 0.785733\tvalid_1's auc: 0.783618\n",
      "[170]\ttraining's auc: 0.78577\tvalid_1's auc: 0.783637\n",
      "[171]\ttraining's auc: 0.785821\tvalid_1's auc: 0.783667\n",
      "[172]\ttraining's auc: 0.785872\tvalid_1's auc: 0.783693\n",
      "[173]\ttraining's auc: 0.785925\tvalid_1's auc: 0.783728\n",
      "[174]\ttraining's auc: 0.78597\tvalid_1's auc: 0.783775\n",
      "[175]\ttraining's auc: 0.786029\tvalid_1's auc: 0.783812\n",
      "[176]\ttraining's auc: 0.786075\tvalid_1's auc: 0.783838\n",
      "[177]\ttraining's auc: 0.786123\tvalid_1's auc: 0.783864\n",
      "[178]\ttraining's auc: 0.786165\tvalid_1's auc: 0.783881\n",
      "[179]\ttraining's auc: 0.786208\tvalid_1's auc: 0.783898\n",
      "[180]\ttraining's auc: 0.786258\tvalid_1's auc: 0.783932\n",
      "[181]\ttraining's auc: 0.786304\tvalid_1's auc: 0.783958\n",
      "[182]\ttraining's auc: 0.786348\tvalid_1's auc: 0.783977\n",
      "[183]\ttraining's auc: 0.786392\tvalid_1's auc: 0.784002\n",
      "[184]\ttraining's auc: 0.786439\tvalid_1's auc: 0.784033\n",
      "[185]\ttraining's auc: 0.786486\tvalid_1's auc: 0.784079\n",
      "[186]\ttraining's auc: 0.786532\tvalid_1's auc: 0.784106\n",
      "[187]\ttraining's auc: 0.786583\tvalid_1's auc: 0.784136\n",
      "[188]\ttraining's auc: 0.786631\tvalid_1's auc: 0.784166\n",
      "[189]\ttraining's auc: 0.786677\tvalid_1's auc: 0.784188\n",
      "[190]\ttraining's auc: 0.786721\tvalid_1's auc: 0.784212\n",
      "[191]\ttraining's auc: 0.786758\tvalid_1's auc: 0.784234\n",
      "[192]\ttraining's auc: 0.78679\tvalid_1's auc: 0.784253\n",
      "[193]\ttraining's auc: 0.786833\tvalid_1's auc: 0.784275\n",
      "[194]\ttraining's auc: 0.78688\tvalid_1's auc: 0.784303\n",
      "[195]\ttraining's auc: 0.786918\tvalid_1's auc: 0.78432\n",
      "[196]\ttraining's auc: 0.786959\tvalid_1's auc: 0.784347\n",
      "[197]\ttraining's auc: 0.787008\tvalid_1's auc: 0.784375\n",
      "[198]\ttraining's auc: 0.787042\tvalid_1's auc: 0.784389\n",
      "[199]\ttraining's auc: 0.787081\tvalid_1's auc: 0.784409\n",
      "[200]\ttraining's auc: 0.787136\tvalid_1's auc: 0.784441\n",
      "[201]\ttraining's auc: 0.787155\tvalid_1's auc: 0.78446\n",
      "[202]\ttraining's auc: 0.787189\tvalid_1's auc: 0.78448\n",
      "[203]\ttraining's auc: 0.787243\tvalid_1's auc: 0.784514\n",
      "[204]\ttraining's auc: 0.787288\tvalid_1's auc: 0.784559\n",
      "[205]\ttraining's auc: 0.787323\tvalid_1's auc: 0.784578\n",
      "[206]\ttraining's auc: 0.787348\tvalid_1's auc: 0.784602\n",
      "[207]\ttraining's auc: 0.787391\tvalid_1's auc: 0.784628\n",
      "[208]\ttraining's auc: 0.787414\tvalid_1's auc: 0.784648\n",
      "[209]\ttraining's auc: 0.78745\tvalid_1's auc: 0.784673\n",
      "[210]\ttraining's auc: 0.787501\tvalid_1's auc: 0.784708\n",
      "[211]\ttraining's auc: 0.787536\tvalid_1's auc: 0.784722\n",
      "[212]\ttraining's auc: 0.78757\tvalid_1's auc: 0.784737\n",
      "[213]\ttraining's auc: 0.787595\tvalid_1's auc: 0.784751\n",
      "[214]\ttraining's auc: 0.787615\tvalid_1's auc: 0.78477\n",
      "[215]\ttraining's auc: 0.787653\tvalid_1's auc: 0.784791\n",
      "[216]\ttraining's auc: 0.787695\tvalid_1's auc: 0.784815\n",
      "[217]\ttraining's auc: 0.787744\tvalid_1's auc: 0.78485\n",
      "[218]\ttraining's auc: 0.787781\tvalid_1's auc: 0.784872\n",
      "[219]\ttraining's auc: 0.787822\tvalid_1's auc: 0.784893\n",
      "[220]\ttraining's auc: 0.787848\tvalid_1's auc: 0.784919\n",
      "[221]\ttraining's auc: 0.787882\tvalid_1's auc: 0.784934\n",
      "[222]\ttraining's auc: 0.78793\tvalid_1's auc: 0.784958\n",
      "[223]\ttraining's auc: 0.787972\tvalid_1's auc: 0.784984\n",
      "[224]\ttraining's auc: 0.78801\tvalid_1's auc: 0.785008\n",
      "[225]\ttraining's auc: 0.788044\tvalid_1's auc: 0.785022\n",
      "[226]\ttraining's auc: 0.788078\tvalid_1's auc: 0.785034\n",
      "[227]\ttraining's auc: 0.788106\tvalid_1's auc: 0.785043\n",
      "[228]\ttraining's auc: 0.788155\tvalid_1's auc: 0.785068\n",
      "[229]\ttraining's auc: 0.78819\tvalid_1's auc: 0.785079\n",
      "[230]\ttraining's auc: 0.788223\tvalid_1's auc: 0.785091\n",
      "[231]\ttraining's auc: 0.788261\tvalid_1's auc: 0.785114\n",
      "[232]\ttraining's auc: 0.7883\tvalid_1's auc: 0.785134\n",
      "[233]\ttraining's auc: 0.788336\tvalid_1's auc: 0.785152\n",
      "[234]\ttraining's auc: 0.788367\tvalid_1's auc: 0.785183\n",
      "[235]\ttraining's auc: 0.788397\tvalid_1's auc: 0.785195\n",
      "[236]\ttraining's auc: 0.788426\tvalid_1's auc: 0.785207\n",
      "[237]\ttraining's auc: 0.788447\tvalid_1's auc: 0.785228\n",
      "[238]\ttraining's auc: 0.788483\tvalid_1's auc: 0.785248\n",
      "[239]\ttraining's auc: 0.78852\tvalid_1's auc: 0.785266\n",
      "[240]\ttraining's auc: 0.788554\tvalid_1's auc: 0.785281\n",
      "[241]\ttraining's auc: 0.788582\tvalid_1's auc: 0.785308\n",
      "[242]\ttraining's auc: 0.78863\tvalid_1's auc: 0.785332\n",
      "[243]\ttraining's auc: 0.78866\tvalid_1's auc: 0.78534\n",
      "[244]\ttraining's auc: 0.788694\tvalid_1's auc: 0.785361\n",
      "[245]\ttraining's auc: 0.788725\tvalid_1's auc: 0.785371\n",
      "[246]\ttraining's auc: 0.788752\tvalid_1's auc: 0.78538\n",
      "[247]\ttraining's auc: 0.788784\tvalid_1's auc: 0.785389\n",
      "[248]\ttraining's auc: 0.788811\tvalid_1's auc: 0.785405\n",
      "[249]\ttraining's auc: 0.788847\tvalid_1's auc: 0.785426\n",
      "[250]\ttraining's auc: 0.788875\tvalid_1's auc: 0.785454\n",
      "[251]\ttraining's auc: 0.788903\tvalid_1's auc: 0.785462\n",
      "[252]\ttraining's auc: 0.788931\tvalid_1's auc: 0.785471\n",
      "[253]\ttraining's auc: 0.788948\tvalid_1's auc: 0.785489\n",
      "[254]\ttraining's auc: 0.788981\tvalid_1's auc: 0.785498\n",
      "[255]\ttraining's auc: 0.789012\tvalid_1's auc: 0.785517\n",
      "[256]\ttraining's auc: 0.789046\tvalid_1's auc: 0.785535\n",
      "[257]\ttraining's auc: 0.789089\tvalid_1's auc: 0.785553\n",
      "[258]\ttraining's auc: 0.789123\tvalid_1's auc: 0.785576\n",
      "[259]\ttraining's auc: 0.789142\tvalid_1's auc: 0.785593\n",
      "[260]\ttraining's auc: 0.789175\tvalid_1's auc: 0.785608\n",
      "[261]\ttraining's auc: 0.789201\tvalid_1's auc: 0.785618\n",
      "[262]\ttraining's auc: 0.789226\tvalid_1's auc: 0.78563\n",
      "[263]\ttraining's auc: 0.789263\tvalid_1's auc: 0.785648\n",
      "[264]\ttraining's auc: 0.789276\tvalid_1's auc: 0.785659\n",
      "[265]\ttraining's auc: 0.789305\tvalid_1's auc: 0.785666\n",
      "[266]\ttraining's auc: 0.789318\tvalid_1's auc: 0.785677\n",
      "[267]\ttraining's auc: 0.789344\tvalid_1's auc: 0.785682\n",
      "[268]\ttraining's auc: 0.78938\tvalid_1's auc: 0.785704\n",
      "[269]\ttraining's auc: 0.789411\tvalid_1's auc: 0.785714\n",
      "[270]\ttraining's auc: 0.789453\tvalid_1's auc: 0.785731\n",
      "[271]\ttraining's auc: 0.789494\tvalid_1's auc: 0.785746\n",
      "[272]\ttraining's auc: 0.789524\tvalid_1's auc: 0.785761\n",
      "[273]\ttraining's auc: 0.789552\tvalid_1's auc: 0.785772\n",
      "[274]\ttraining's auc: 0.789582\tvalid_1's auc: 0.785789\n",
      "[275]\ttraining's auc: 0.789609\tvalid_1's auc: 0.785799\n",
      "[276]\ttraining's auc: 0.789641\tvalid_1's auc: 0.78582\n",
      "[277]\ttraining's auc: 0.789668\tvalid_1's auc: 0.785826\n",
      "[278]\ttraining's auc: 0.789699\tvalid_1's auc: 0.785841\n",
      "[279]\ttraining's auc: 0.789738\tvalid_1's auc: 0.78588\n",
      "[280]\ttraining's auc: 0.789765\tvalid_1's auc: 0.785887\n",
      "[281]\ttraining's auc: 0.789782\tvalid_1's auc: 0.785904\n",
      "[282]\ttraining's auc: 0.789803\tvalid_1's auc: 0.785909\n",
      "[283]\ttraining's auc: 0.789825\tvalid_1's auc: 0.785919\n",
      "[284]\ttraining's auc: 0.789851\tvalid_1's auc: 0.785929\n",
      "[285]\ttraining's auc: 0.78988\tvalid_1's auc: 0.785937\n",
      "[286]\ttraining's auc: 0.789903\tvalid_1's auc: 0.785944\n",
      "[287]\ttraining's auc: 0.789932\tvalid_1's auc: 0.785954\n",
      "[288]\ttraining's auc: 0.789958\tvalid_1's auc: 0.785965\n",
      "[289]\ttraining's auc: 0.789981\tvalid_1's auc: 0.785974\n",
      "[290]\ttraining's auc: 0.790006\tvalid_1's auc: 0.785984\n",
      "[291]\ttraining's auc: 0.790037\tvalid_1's auc: 0.785999\n",
      "[292]\ttraining's auc: 0.790054\tvalid_1's auc: 0.786015\n",
      "[293]\ttraining's auc: 0.790073\tvalid_1's auc: 0.786022\n",
      "[294]\ttraining's auc: 0.790111\tvalid_1's auc: 0.786035\n",
      "[295]\ttraining's auc: 0.790123\tvalid_1's auc: 0.786046\n",
      "[296]\ttraining's auc: 0.790141\tvalid_1's auc: 0.786049\n",
      "[297]\ttraining's auc: 0.790164\tvalid_1's auc: 0.786054\n",
      "[298]\ttraining's auc: 0.790181\tvalid_1's auc: 0.78607\n",
      "[299]\ttraining's auc: 0.790198\tvalid_1's auc: 0.786072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's auc: 0.790228\tvalid_1's auc: 0.786086\n",
      "[301]\ttraining's auc: 0.790251\tvalid_1's auc: 0.78609\n",
      "[302]\ttraining's auc: 0.790268\tvalid_1's auc: 0.786106\n",
      "[303]\ttraining's auc: 0.790284\tvalid_1's auc: 0.786121\n",
      "[304]\ttraining's auc: 0.790306\tvalid_1's auc: 0.786128\n",
      "[305]\ttraining's auc: 0.790329\tvalid_1's auc: 0.786136\n",
      "[306]\ttraining's auc: 0.790359\tvalid_1's auc: 0.78615\n",
      "[307]\ttraining's auc: 0.790382\tvalid_1's auc: 0.786155\n",
      "[308]\ttraining's auc: 0.790406\tvalid_1's auc: 0.786163\n",
      "[309]\ttraining's auc: 0.790429\tvalid_1's auc: 0.786172\n",
      "[310]\ttraining's auc: 0.790453\tvalid_1's auc: 0.786179\n",
      "[311]\ttraining's auc: 0.790481\tvalid_1's auc: 0.786207\n",
      "[312]\ttraining's auc: 0.790506\tvalid_1's auc: 0.786214\n",
      "[313]\ttraining's auc: 0.790525\tvalid_1's auc: 0.786219\n",
      "[314]\ttraining's auc: 0.790546\tvalid_1's auc: 0.786226\n",
      "[315]\ttraining's auc: 0.790572\tvalid_1's auc: 0.786232\n",
      "[316]\ttraining's auc: 0.790601\tvalid_1's auc: 0.786247\n",
      "[317]\ttraining's auc: 0.790617\tvalid_1's auc: 0.786252\n",
      "[318]\ttraining's auc: 0.790638\tvalid_1's auc: 0.786255\n",
      "[319]\ttraining's auc: 0.790662\tvalid_1's auc: 0.786263\n",
      "[320]\ttraining's auc: 0.790681\tvalid_1's auc: 0.786281\n",
      "[321]\ttraining's auc: 0.79071\tvalid_1's auc: 0.786295\n",
      "[322]\ttraining's auc: 0.790732\tvalid_1's auc: 0.786299\n",
      "[323]\ttraining's auc: 0.790765\tvalid_1's auc: 0.786307\n",
      "[324]\ttraining's auc: 0.790784\tvalid_1's auc: 0.786309\n",
      "[325]\ttraining's auc: 0.790806\tvalid_1's auc: 0.786317\n",
      "[326]\ttraining's auc: 0.790828\tvalid_1's auc: 0.786324\n",
      "[327]\ttraining's auc: 0.790845\tvalid_1's auc: 0.786326\n",
      "[328]\ttraining's auc: 0.790861\tvalid_1's auc: 0.786339\n",
      "[329]\ttraining's auc: 0.790879\tvalid_1's auc: 0.786343\n",
      "[330]\ttraining's auc: 0.790904\tvalid_1's auc: 0.786353\n",
      "[331]\ttraining's auc: 0.790924\tvalid_1's auc: 0.786359\n",
      "[332]\ttraining's auc: 0.790941\tvalid_1's auc: 0.78636\n",
      "[333]\ttraining's auc: 0.79096\tvalid_1's auc: 0.786363\n",
      "[334]\ttraining's auc: 0.790982\tvalid_1's auc: 0.786367\n",
      "[335]\ttraining's auc: 0.791014\tvalid_1's auc: 0.786377\n",
      "[336]\ttraining's auc: 0.791036\tvalid_1's auc: 0.786383\n",
      "[337]\ttraining's auc: 0.791057\tvalid_1's auc: 0.786394\n",
      "[338]\ttraining's auc: 0.791073\tvalid_1's auc: 0.786409\n",
      "[339]\ttraining's auc: 0.791089\tvalid_1's auc: 0.786424\n",
      "[340]\ttraining's auc: 0.791119\tvalid_1's auc: 0.786431\n",
      "[341]\ttraining's auc: 0.79115\tvalid_1's auc: 0.78644\n",
      "[342]\ttraining's auc: 0.791165\tvalid_1's auc: 0.786445\n",
      "[343]\ttraining's auc: 0.791181\tvalid_1's auc: 0.786451\n",
      "[344]\ttraining's auc: 0.7912\tvalid_1's auc: 0.786456\n",
      "[345]\ttraining's auc: 0.791213\tvalid_1's auc: 0.786457\n",
      "[346]\ttraining's auc: 0.791235\tvalid_1's auc: 0.786469\n",
      "[347]\ttraining's auc: 0.791248\tvalid_1's auc: 0.786481\n",
      "[348]\ttraining's auc: 0.791269\tvalid_1's auc: 0.786486\n",
      "[349]\ttraining's auc: 0.791291\tvalid_1's auc: 0.786495\n",
      "[350]\ttraining's auc: 0.791305\tvalid_1's auc: 0.786508\n",
      "[351]\ttraining's auc: 0.791329\tvalid_1's auc: 0.786516\n",
      "[352]\ttraining's auc: 0.791351\tvalid_1's auc: 0.786538\n",
      "[353]\ttraining's auc: 0.791371\tvalid_1's auc: 0.786543\n",
      "[354]\ttraining's auc: 0.791382\tvalid_1's auc: 0.786553\n",
      "[355]\ttraining's auc: 0.791395\tvalid_1's auc: 0.786565\n",
      "[356]\ttraining's auc: 0.791424\tvalid_1's auc: 0.786573\n",
      "[357]\ttraining's auc: 0.791442\tvalid_1's auc: 0.786577\n",
      "[358]\ttraining's auc: 0.791468\tvalid_1's auc: 0.786588\n",
      "[359]\ttraining's auc: 0.791492\tvalid_1's auc: 0.786592\n",
      "[360]\ttraining's auc: 0.791508\tvalid_1's auc: 0.786595\n",
      "[361]\ttraining's auc: 0.791537\tvalid_1's auc: 0.786603\n",
      "[362]\ttraining's auc: 0.79155\tvalid_1's auc: 0.786605\n",
      "[363]\ttraining's auc: 0.79157\tvalid_1's auc: 0.786615\n",
      "[364]\ttraining's auc: 0.791588\tvalid_1's auc: 0.78662\n",
      "[365]\ttraining's auc: 0.791611\tvalid_1's auc: 0.786625\n",
      "[366]\ttraining's auc: 0.791622\tvalid_1's auc: 0.786625\n",
      "[367]\ttraining's auc: 0.79164\tvalid_1's auc: 0.78663\n",
      "[368]\ttraining's auc: 0.791656\tvalid_1's auc: 0.786634\n",
      "[369]\ttraining's auc: 0.791669\tvalid_1's auc: 0.786646\n",
      "[370]\ttraining's auc: 0.791678\tvalid_1's auc: 0.786655\n",
      "[371]\ttraining's auc: 0.791691\tvalid_1's auc: 0.786668\n",
      "[372]\ttraining's auc: 0.791705\tvalid_1's auc: 0.786673\n",
      "[373]\ttraining's auc: 0.791716\tvalid_1's auc: 0.786682\n",
      "[374]\ttraining's auc: 0.791734\tvalid_1's auc: 0.786687\n",
      "[375]\ttraining's auc: 0.791748\tvalid_1's auc: 0.786689\n",
      "[376]\ttraining's auc: 0.79178\tvalid_1's auc: 0.786697\n",
      "[377]\ttraining's auc: 0.791795\tvalid_1's auc: 0.786701\n",
      "[378]\ttraining's auc: 0.791808\tvalid_1's auc: 0.786703\n",
      "[379]\ttraining's auc: 0.791834\tvalid_1's auc: 0.78671\n",
      "[380]\ttraining's auc: 0.791853\tvalid_1's auc: 0.786711\n",
      "[381]\ttraining's auc: 0.791871\tvalid_1's auc: 0.786718\n",
      "[382]\ttraining's auc: 0.791897\tvalid_1's auc: 0.786728\n",
      "[383]\ttraining's auc: 0.791918\tvalid_1's auc: 0.786748\n",
      "[384]\ttraining's auc: 0.791934\tvalid_1's auc: 0.786748\n",
      "[385]\ttraining's auc: 0.791955\tvalid_1's auc: 0.786758\n",
      "[386]\ttraining's auc: 0.791984\tvalid_1's auc: 0.786772\n",
      "[387]\ttraining's auc: 0.791995\tvalid_1's auc: 0.786771\n",
      "[388]\ttraining's auc: 0.792008\tvalid_1's auc: 0.786771\n",
      "[389]\ttraining's auc: 0.792026\tvalid_1's auc: 0.786787\n",
      "[390]\ttraining's auc: 0.792043\tvalid_1's auc: 0.786791\n",
      "[391]\ttraining's auc: 0.792055\tvalid_1's auc: 0.786801\n",
      "[392]\ttraining's auc: 0.792067\tvalid_1's auc: 0.786812\n",
      "[393]\ttraining's auc: 0.79208\tvalid_1's auc: 0.786823\n",
      "[394]\ttraining's auc: 0.7921\tvalid_1's auc: 0.786834\n",
      "[395]\ttraining's auc: 0.792111\tvalid_1's auc: 0.786837\n",
      "[396]\ttraining's auc: 0.792126\tvalid_1's auc: 0.786852\n",
      "[397]\ttraining's auc: 0.792136\tvalid_1's auc: 0.786851\n",
      "[398]\ttraining's auc: 0.792151\tvalid_1's auc: 0.786855\n",
      "[399]\ttraining's auc: 0.79216\tvalid_1's auc: 0.786863\n",
      "[400]\ttraining's auc: 0.792176\tvalid_1's auc: 0.78687\n",
      "[401]\ttraining's auc: 0.792186\tvalid_1's auc: 0.78687\n",
      "[402]\ttraining's auc: 0.792204\tvalid_1's auc: 0.786873\n",
      "[403]\ttraining's auc: 0.792216\tvalid_1's auc: 0.786885\n",
      "[404]\ttraining's auc: 0.792237\tvalid_1's auc: 0.786894\n",
      "[405]\ttraining's auc: 0.79226\tvalid_1's auc: 0.786898\n",
      "[406]\ttraining's auc: 0.792272\tvalid_1's auc: 0.786909\n",
      "[407]\ttraining's auc: 0.792287\tvalid_1's auc: 0.786916\n",
      "[408]\ttraining's auc: 0.792307\tvalid_1's auc: 0.786927\n",
      "[409]\ttraining's auc: 0.792323\tvalid_1's auc: 0.786931\n",
      "[410]\ttraining's auc: 0.792333\tvalid_1's auc: 0.78693\n",
      "[411]\ttraining's auc: 0.792346\tvalid_1's auc: 0.786941\n",
      "[412]\ttraining's auc: 0.79236\tvalid_1's auc: 0.786945\n",
      "[413]\ttraining's auc: 0.792371\tvalid_1's auc: 0.786944\n",
      "[414]\ttraining's auc: 0.792381\tvalid_1's auc: 0.786944\n",
      "[415]\ttraining's auc: 0.792394\tvalid_1's auc: 0.786946\n",
      "[416]\ttraining's auc: 0.792407\tvalid_1's auc: 0.786957\n",
      "[417]\ttraining's auc: 0.792424\tvalid_1's auc: 0.786962\n",
      "[418]\ttraining's auc: 0.792439\tvalid_1's auc: 0.786965\n",
      "[419]\ttraining's auc: 0.79245\tvalid_1's auc: 0.786975\n",
      "[420]\ttraining's auc: 0.79246\tvalid_1's auc: 0.786977\n",
      "[421]\ttraining's auc: 0.792478\tvalid_1's auc: 0.786994\n",
      "[422]\ttraining's auc: 0.792506\tvalid_1's auc: 0.78701\n",
      "[423]\ttraining's auc: 0.792521\tvalid_1's auc: 0.787013\n",
      "[424]\ttraining's auc: 0.792534\tvalid_1's auc: 0.787015\n",
      "[425]\ttraining's auc: 0.792549\tvalid_1's auc: 0.78702\n",
      "[426]\ttraining's auc: 0.79256\tvalid_1's auc: 0.787024\n",
      "[427]\ttraining's auc: 0.792574\tvalid_1's auc: 0.787024\n",
      "[428]\ttraining's auc: 0.792584\tvalid_1's auc: 0.787024\n",
      "[429]\ttraining's auc: 0.792596\tvalid_1's auc: 0.787027\n",
      "[430]\ttraining's auc: 0.792604\tvalid_1's auc: 0.787033\n",
      "[431]\ttraining's auc: 0.792627\tvalid_1's auc: 0.787047\n",
      "[432]\ttraining's auc: 0.792636\tvalid_1's auc: 0.787055\n",
      "[433]\ttraining's auc: 0.792646\tvalid_1's auc: 0.787063\n",
      "[434]\ttraining's auc: 0.792662\tvalid_1's auc: 0.787064\n",
      "[435]\ttraining's auc: 0.79269\tvalid_1's auc: 0.787076\n",
      "[436]\ttraining's auc: 0.792706\tvalid_1's auc: 0.787082\n",
      "[437]\ttraining's auc: 0.792715\tvalid_1's auc: 0.787088\n",
      "[438]\ttraining's auc: 0.792728\tvalid_1's auc: 0.787092\n",
      "[439]\ttraining's auc: 0.79274\tvalid_1's auc: 0.787091\n",
      "[440]\ttraining's auc: 0.792758\tvalid_1's auc: 0.787109\n",
      "[441]\ttraining's auc: 0.792779\tvalid_1's auc: 0.787119\n",
      "[442]\ttraining's auc: 0.792788\tvalid_1's auc: 0.787128\n",
      "[443]\ttraining's auc: 0.792805\tvalid_1's auc: 0.78713\n",
      "[444]\ttraining's auc: 0.792814\tvalid_1's auc: 0.787132\n",
      "[445]\ttraining's auc: 0.792826\tvalid_1's auc: 0.787143\n",
      "[446]\ttraining's auc: 0.792842\tvalid_1's auc: 0.787148\n",
      "[447]\ttraining's auc: 0.792855\tvalid_1's auc: 0.787158\n",
      "[448]\ttraining's auc: 0.792876\tvalid_1's auc: 0.787167\n",
      "[449]\ttraining's auc: 0.792901\tvalid_1's auc: 0.787175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\ttraining's auc: 0.792918\tvalid_1's auc: 0.787193\n",
      "[451]\ttraining's auc: 0.792933\tvalid_1's auc: 0.787195\n",
      "[452]\ttraining's auc: 0.792955\tvalid_1's auc: 0.787208\n",
      "[453]\ttraining's auc: 0.792972\tvalid_1's auc: 0.787213\n",
      "[454]\ttraining's auc: 0.79299\tvalid_1's auc: 0.787217\n",
      "[455]\ttraining's auc: 0.793\tvalid_1's auc: 0.787217\n",
      "[456]\ttraining's auc: 0.793018\tvalid_1's auc: 0.787225\n",
      "[457]\ttraining's auc: 0.79303\tvalid_1's auc: 0.787227\n",
      "[458]\ttraining's auc: 0.793044\tvalid_1's auc: 0.787229\n",
      "[459]\ttraining's auc: 0.793053\tvalid_1's auc: 0.787236\n",
      "[460]\ttraining's auc: 0.793061\tvalid_1's auc: 0.787237\n",
      "[461]\ttraining's auc: 0.79308\tvalid_1's auc: 0.787244\n",
      "[462]\ttraining's auc: 0.79309\tvalid_1's auc: 0.787253\n",
      "[463]\ttraining's auc: 0.793101\tvalid_1's auc: 0.787252\n",
      "[464]\ttraining's auc: 0.793113\tvalid_1's auc: 0.787262\n",
      "[465]\ttraining's auc: 0.79312\tvalid_1's auc: 0.787265\n",
      "[466]\ttraining's auc: 0.79313\tvalid_1's auc: 0.787266\n",
      "[467]\ttraining's auc: 0.793153\tvalid_1's auc: 0.787271\n",
      "[468]\ttraining's auc: 0.793163\tvalid_1's auc: 0.787273\n",
      "[469]\ttraining's auc: 0.793172\tvalid_1's auc: 0.787276\n",
      "[470]\ttraining's auc: 0.793189\tvalid_1's auc: 0.787286\n",
      "[471]\ttraining's auc: 0.793199\tvalid_1's auc: 0.78729\n",
      "[472]\ttraining's auc: 0.793209\tvalid_1's auc: 0.787291\n",
      "[473]\ttraining's auc: 0.793226\tvalid_1's auc: 0.787303\n",
      "[474]\ttraining's auc: 0.793234\tvalid_1's auc: 0.78731\n",
      "[475]\ttraining's auc: 0.793246\tvalid_1's auc: 0.787321\n",
      "[476]\ttraining's auc: 0.793258\tvalid_1's auc: 0.787323\n",
      "[477]\ttraining's auc: 0.793272\tvalid_1's auc: 0.787328\n",
      "[478]\ttraining's auc: 0.793286\tvalid_1's auc: 0.787333\n",
      "[479]\ttraining's auc: 0.793294\tvalid_1's auc: 0.78734\n",
      "[480]\ttraining's auc: 0.793303\tvalid_1's auc: 0.78734\n",
      "[481]\ttraining's auc: 0.793313\tvalid_1's auc: 0.787339\n",
      "[482]\ttraining's auc: 0.793321\tvalid_1's auc: 0.787346\n",
      "[483]\ttraining's auc: 0.793338\tvalid_1's auc: 0.787348\n",
      "[484]\ttraining's auc: 0.793356\tvalid_1's auc: 0.787352\n",
      "[485]\ttraining's auc: 0.793364\tvalid_1's auc: 0.787357\n",
      "[486]\ttraining's auc: 0.793371\tvalid_1's auc: 0.787359\n",
      "[487]\ttraining's auc: 0.793382\tvalid_1's auc: 0.787359\n",
      "[488]\ttraining's auc: 0.793394\tvalid_1's auc: 0.78736\n",
      "[489]\ttraining's auc: 0.793402\tvalid_1's auc: 0.787367\n",
      "[490]\ttraining's auc: 0.793411\tvalid_1's auc: 0.787368\n",
      "[491]\ttraining's auc: 0.79342\tvalid_1's auc: 0.787368\n",
      "[492]\ttraining's auc: 0.793431\tvalid_1's auc: 0.787379\n",
      "[493]\ttraining's auc: 0.793439\tvalid_1's auc: 0.787381\n",
      "[494]\ttraining's auc: 0.793446\tvalid_1's auc: 0.787381\n",
      "[495]\ttraining's auc: 0.79346\tvalid_1's auc: 0.787382\n",
      "[496]\ttraining's auc: 0.793471\tvalid_1's auc: 0.787382\n",
      "[497]\ttraining's auc: 0.793479\tvalid_1's auc: 0.787383\n",
      "[498]\ttraining's auc: 0.79349\tvalid_1's auc: 0.787392\n",
      "[499]\ttraining's auc: 0.793494\tvalid_1's auc: 0.787396\n",
      "[500]\ttraining's auc: 0.793509\tvalid_1's auc: 0.787402\n",
      "[501]\ttraining's auc: 0.79352\tvalid_1's auc: 0.787409\n",
      "[502]\ttraining's auc: 0.793527\tvalid_1's auc: 0.787409\n",
      "[503]\ttraining's auc: 0.79353\tvalid_1's auc: 0.787411\n",
      "[504]\ttraining's auc: 0.793543\tvalid_1's auc: 0.787417\n",
      "[505]\ttraining's auc: 0.793559\tvalid_1's auc: 0.787421\n",
      "[506]\ttraining's auc: 0.79357\tvalid_1's auc: 0.787424\n",
      "[507]\ttraining's auc: 0.79358\tvalid_1's auc: 0.787423\n",
      "[508]\ttraining's auc: 0.793589\tvalid_1's auc: 0.787428\n",
      "[509]\ttraining's auc: 0.793597\tvalid_1's auc: 0.787428\n",
      "[510]\ttraining's auc: 0.793612\tvalid_1's auc: 0.787434\n",
      "[511]\ttraining's auc: 0.793629\tvalid_1's auc: 0.787436\n",
      "[512]\ttraining's auc: 0.793643\tvalid_1's auc: 0.78744\n",
      "[513]\ttraining's auc: 0.793658\tvalid_1's auc: 0.787443\n",
      "[514]\ttraining's auc: 0.793673\tvalid_1's auc: 0.787444\n",
      "[515]\ttraining's auc: 0.793681\tvalid_1's auc: 0.787445\n",
      "[516]\ttraining's auc: 0.793693\tvalid_1's auc: 0.787448\n",
      "[517]\ttraining's auc: 0.793711\tvalid_1's auc: 0.787453\n",
      "[518]\ttraining's auc: 0.793718\tvalid_1's auc: 0.787458\n",
      "[519]\ttraining's auc: 0.793726\tvalid_1's auc: 0.78746\n",
      "[520]\ttraining's auc: 0.793743\tvalid_1's auc: 0.787466\n",
      "[521]\ttraining's auc: 0.79376\tvalid_1's auc: 0.787471\n",
      "[522]\ttraining's auc: 0.793777\tvalid_1's auc: 0.787473\n",
      "[523]\ttraining's auc: 0.79379\tvalid_1's auc: 0.787474\n",
      "[524]\ttraining's auc: 0.793799\tvalid_1's auc: 0.787474\n",
      "[525]\ttraining's auc: 0.79381\tvalid_1's auc: 0.787484\n",
      "[526]\ttraining's auc: 0.793825\tvalid_1's auc: 0.787489\n",
      "[527]\ttraining's auc: 0.793833\tvalid_1's auc: 0.787496\n",
      "[528]\ttraining's auc: 0.79384\tvalid_1's auc: 0.787497\n",
      "[529]\ttraining's auc: 0.793847\tvalid_1's auc: 0.787497\n",
      "[530]\ttraining's auc: 0.79386\tvalid_1's auc: 0.787499\n",
      "[531]\ttraining's auc: 0.793871\tvalid_1's auc: 0.787498\n",
      "[532]\ttraining's auc: 0.793876\tvalid_1's auc: 0.787497\n",
      "[533]\ttraining's auc: 0.793887\tvalid_1's auc: 0.787501\n",
      "[534]\ttraining's auc: 0.793893\tvalid_1's auc: 0.787501\n",
      "[535]\ttraining's auc: 0.793908\tvalid_1's auc: 0.787506\n",
      "[536]\ttraining's auc: 0.79392\tvalid_1's auc: 0.787508\n",
      "[537]\ttraining's auc: 0.79393\tvalid_1's auc: 0.787517\n",
      "[538]\ttraining's auc: 0.793945\tvalid_1's auc: 0.787518\n",
      "[539]\ttraining's auc: 0.793957\tvalid_1's auc: 0.78752\n",
      "[540]\ttraining's auc: 0.79397\tvalid_1's auc: 0.787522\n",
      "[541]\ttraining's auc: 0.79398\tvalid_1's auc: 0.787526\n",
      "[542]\ttraining's auc: 0.793991\tvalid_1's auc: 0.787528\n",
      "[543]\ttraining's auc: 0.794002\tvalid_1's auc: 0.787528\n",
      "[544]\ttraining's auc: 0.794012\tvalid_1's auc: 0.787528\n",
      "[545]\ttraining's auc: 0.794017\tvalid_1's auc: 0.787529\n",
      "[546]\ttraining's auc: 0.794031\tvalid_1's auc: 0.787531\n",
      "[547]\ttraining's auc: 0.794042\tvalid_1's auc: 0.787533\n",
      "[548]\ttraining's auc: 0.794048\tvalid_1's auc: 0.787538\n",
      "[549]\ttraining's auc: 0.794062\tvalid_1's auc: 0.787539\n",
      "[550]\ttraining's auc: 0.794068\tvalid_1's auc: 0.787545\n",
      "[551]\ttraining's auc: 0.794073\tvalid_1's auc: 0.787549\n",
      "[552]\ttraining's auc: 0.794086\tvalid_1's auc: 0.787555\n",
      "[553]\ttraining's auc: 0.794098\tvalid_1's auc: 0.787558\n",
      "[554]\ttraining's auc: 0.794102\tvalid_1's auc: 0.787559\n",
      "[555]\ttraining's auc: 0.794113\tvalid_1's auc: 0.78756\n",
      "[556]\ttraining's auc: 0.794122\tvalid_1's auc: 0.787561\n",
      "[557]\ttraining's auc: 0.794133\tvalid_1's auc: 0.787562\n",
      "[558]\ttraining's auc: 0.794137\tvalid_1's auc: 0.787565\n",
      "[559]\ttraining's auc: 0.794144\tvalid_1's auc: 0.787565\n",
      "[560]\ttraining's auc: 0.79416\tvalid_1's auc: 0.787574\n",
      "[561]\ttraining's auc: 0.794175\tvalid_1's auc: 0.787577\n",
      "[562]\ttraining's auc: 0.79418\tvalid_1's auc: 0.78758\n",
      "[563]\ttraining's auc: 0.794191\tvalid_1's auc: 0.78758\n",
      "[564]\ttraining's auc: 0.794199\tvalid_1's auc: 0.787581\n",
      "[565]\ttraining's auc: 0.794211\tvalid_1's auc: 0.787582\n",
      "[566]\ttraining's auc: 0.794217\tvalid_1's auc: 0.787582\n",
      "[567]\ttraining's auc: 0.79423\tvalid_1's auc: 0.787586\n",
      "[568]\ttraining's auc: 0.794237\tvalid_1's auc: 0.787585\n",
      "[569]\ttraining's auc: 0.794243\tvalid_1's auc: 0.787585\n",
      "[570]\ttraining's auc: 0.794258\tvalid_1's auc: 0.787588\n",
      "[571]\ttraining's auc: 0.794265\tvalid_1's auc: 0.787593\n",
      "[572]\ttraining's auc: 0.794277\tvalid_1's auc: 0.787596\n",
      "[573]\ttraining's auc: 0.794302\tvalid_1's auc: 0.7876\n",
      "[574]\ttraining's auc: 0.794314\tvalid_1's auc: 0.787604\n",
      "[575]\ttraining's auc: 0.794317\tvalid_1's auc: 0.787606\n",
      "[576]\ttraining's auc: 0.79433\tvalid_1's auc: 0.787618\n",
      "[577]\ttraining's auc: 0.79434\tvalid_1's auc: 0.787623\n",
      "[578]\ttraining's auc: 0.794349\tvalid_1's auc: 0.787631\n",
      "[579]\ttraining's auc: 0.794363\tvalid_1's auc: 0.787635\n",
      "[580]\ttraining's auc: 0.794371\tvalid_1's auc: 0.787637\n",
      "[581]\ttraining's auc: 0.794382\tvalid_1's auc: 0.787642\n",
      "[582]\ttraining's auc: 0.794386\tvalid_1's auc: 0.787645\n",
      "[583]\ttraining's auc: 0.794394\tvalid_1's auc: 0.787651\n",
      "[584]\ttraining's auc: 0.794407\tvalid_1's auc: 0.787654\n",
      "[585]\ttraining's auc: 0.794416\tvalid_1's auc: 0.787656\n",
      "[586]\ttraining's auc: 0.794426\tvalid_1's auc: 0.787657\n",
      "[587]\ttraining's auc: 0.794443\tvalid_1's auc: 0.787669\n",
      "[588]\ttraining's auc: 0.794458\tvalid_1's auc: 0.787672\n",
      "[589]\ttraining's auc: 0.794481\tvalid_1's auc: 0.787676\n",
      "[590]\ttraining's auc: 0.794496\tvalid_1's auc: 0.78768\n",
      "[591]\ttraining's auc: 0.794517\tvalid_1's auc: 0.787682\n",
      "[592]\ttraining's auc: 0.794527\tvalid_1's auc: 0.787681\n",
      "[593]\ttraining's auc: 0.794533\tvalid_1's auc: 0.787681\n",
      "[594]\ttraining's auc: 0.794543\tvalid_1's auc: 0.787685\n",
      "[595]\ttraining's auc: 0.794551\tvalid_1's auc: 0.787686\n",
      "[596]\ttraining's auc: 0.794558\tvalid_1's auc: 0.787692\n",
      "[597]\ttraining's auc: 0.794576\tvalid_1's auc: 0.787692\n",
      "[598]\ttraining's auc: 0.794581\tvalid_1's auc: 0.787692\n",
      "[599]\ttraining's auc: 0.794589\tvalid_1's auc: 0.787693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's auc: 0.794599\tvalid_1's auc: 0.787694\n",
      "[601]\ttraining's auc: 0.794606\tvalid_1's auc: 0.787694\n",
      "[602]\ttraining's auc: 0.794614\tvalid_1's auc: 0.787702\n",
      "[603]\ttraining's auc: 0.794623\tvalid_1's auc: 0.787709\n",
      "[604]\ttraining's auc: 0.794627\tvalid_1's auc: 0.787709\n",
      "[605]\ttraining's auc: 0.794633\tvalid_1's auc: 0.787709\n",
      "[606]\ttraining's auc: 0.794641\tvalid_1's auc: 0.787709\n",
      "[607]\ttraining's auc: 0.794646\tvalid_1's auc: 0.787708\n",
      "[608]\ttraining's auc: 0.794659\tvalid_1's auc: 0.787717\n",
      "[609]\ttraining's auc: 0.794663\tvalid_1's auc: 0.787717\n",
      "[610]\ttraining's auc: 0.794667\tvalid_1's auc: 0.787718\n",
      "[611]\ttraining's auc: 0.794681\tvalid_1's auc: 0.78772\n",
      "[612]\ttraining's auc: 0.794699\tvalid_1's auc: 0.787725\n",
      "[613]\ttraining's auc: 0.794707\tvalid_1's auc: 0.787727\n",
      "[614]\ttraining's auc: 0.794712\tvalid_1's auc: 0.78773\n",
      "[615]\ttraining's auc: 0.794719\tvalid_1's auc: 0.787736\n",
      "[616]\ttraining's auc: 0.79474\tvalid_1's auc: 0.787738\n",
      "[617]\ttraining's auc: 0.79475\tvalid_1's auc: 0.787745\n",
      "[618]\ttraining's auc: 0.794758\tvalid_1's auc: 0.787746\n",
      "[619]\ttraining's auc: 0.794765\tvalid_1's auc: 0.787746\n",
      "[620]\ttraining's auc: 0.794769\tvalid_1's auc: 0.787748\n",
      "[621]\ttraining's auc: 0.794774\tvalid_1's auc: 0.787749\n",
      "[622]\ttraining's auc: 0.794788\tvalid_1's auc: 0.787749\n",
      "[623]\ttraining's auc: 0.794797\tvalid_1's auc: 0.787752\n",
      "[624]\ttraining's auc: 0.794812\tvalid_1's auc: 0.787753\n",
      "[625]\ttraining's auc: 0.794815\tvalid_1's auc: 0.787753\n",
      "[626]\ttraining's auc: 0.794839\tvalid_1's auc: 0.787757\n",
      "[627]\ttraining's auc: 0.794849\tvalid_1's auc: 0.787759\n",
      "[628]\ttraining's auc: 0.794857\tvalid_1's auc: 0.787759\n",
      "[629]\ttraining's auc: 0.794871\tvalid_1's auc: 0.787764\n",
      "[630]\ttraining's auc: 0.794883\tvalid_1's auc: 0.787766\n",
      "[631]\ttraining's auc: 0.794897\tvalid_1's auc: 0.787767\n",
      "[632]\ttraining's auc: 0.794905\tvalid_1's auc: 0.787768\n",
      "[633]\ttraining's auc: 0.794925\tvalid_1's auc: 0.787773\n",
      "[634]\ttraining's auc: 0.794939\tvalid_1's auc: 0.787774\n",
      "[635]\ttraining's auc: 0.794946\tvalid_1's auc: 0.78778\n",
      "[636]\ttraining's auc: 0.794954\tvalid_1's auc: 0.787781\n",
      "[637]\ttraining's auc: 0.794958\tvalid_1's auc: 0.787783\n",
      "[638]\ttraining's auc: 0.79497\tvalid_1's auc: 0.787787\n",
      "[639]\ttraining's auc: 0.794982\tvalid_1's auc: 0.787791\n",
      "[640]\ttraining's auc: 0.794989\tvalid_1's auc: 0.787797\n",
      "[641]\ttraining's auc: 0.794993\tvalid_1's auc: 0.787799\n",
      "[642]\ttraining's auc: 0.794996\tvalid_1's auc: 0.7878\n",
      "[643]\ttraining's auc: 0.795007\tvalid_1's auc: 0.787801\n",
      "[644]\ttraining's auc: 0.79502\tvalid_1's auc: 0.787808\n",
      "[645]\ttraining's auc: 0.79503\tvalid_1's auc: 0.78781\n",
      "[646]\ttraining's auc: 0.79504\tvalid_1's auc: 0.787817\n",
      "[647]\ttraining's auc: 0.795045\tvalid_1's auc: 0.78782\n",
      "[648]\ttraining's auc: 0.79505\tvalid_1's auc: 0.787825\n",
      "[649]\ttraining's auc: 0.795054\tvalid_1's auc: 0.787824\n",
      "[650]\ttraining's auc: 0.795063\tvalid_1's auc: 0.787825\n",
      "[651]\ttraining's auc: 0.795067\tvalid_1's auc: 0.787826\n",
      "[652]\ttraining's auc: 0.795078\tvalid_1's auc: 0.787826\n",
      "[653]\ttraining's auc: 0.795084\tvalid_1's auc: 0.787826\n",
      "[654]\ttraining's auc: 0.795091\tvalid_1's auc: 0.787832\n",
      "[655]\ttraining's auc: 0.795099\tvalid_1's auc: 0.787834\n",
      "[656]\ttraining's auc: 0.795103\tvalid_1's auc: 0.787834\n",
      "[657]\ttraining's auc: 0.795111\tvalid_1's auc: 0.78784\n",
      "[658]\ttraining's auc: 0.795114\tvalid_1's auc: 0.787841\n",
      "[659]\ttraining's auc: 0.795119\tvalid_1's auc: 0.787843\n",
      "[660]\ttraining's auc: 0.795124\tvalid_1's auc: 0.787844\n",
      "[661]\ttraining's auc: 0.795134\tvalid_1's auc: 0.787844\n",
      "[662]\ttraining's auc: 0.795144\tvalid_1's auc: 0.787847\n",
      "[663]\ttraining's auc: 0.795146\tvalid_1's auc: 0.787847\n",
      "[664]\ttraining's auc: 0.795153\tvalid_1's auc: 0.787847\n",
      "[665]\ttraining's auc: 0.795168\tvalid_1's auc: 0.787854\n",
      "[666]\ttraining's auc: 0.795177\tvalid_1's auc: 0.787863\n",
      "[667]\ttraining's auc: 0.795182\tvalid_1's auc: 0.787866\n",
      "[668]\ttraining's auc: 0.79519\tvalid_1's auc: 0.787874\n",
      "[669]\ttraining's auc: 0.795203\tvalid_1's auc: 0.787887\n",
      "[670]\ttraining's auc: 0.795206\tvalid_1's auc: 0.787887\n",
      "[671]\ttraining's auc: 0.795209\tvalid_1's auc: 0.787886\n",
      "[672]\ttraining's auc: 0.795222\tvalid_1's auc: 0.787895\n",
      "[673]\ttraining's auc: 0.795233\tvalid_1's auc: 0.787897\n",
      "[674]\ttraining's auc: 0.795237\tvalid_1's auc: 0.787897\n",
      "[675]\ttraining's auc: 0.79524\tvalid_1's auc: 0.787897\n",
      "[676]\ttraining's auc: 0.795247\tvalid_1's auc: 0.787897\n",
      "[677]\ttraining's auc: 0.79525\tvalid_1's auc: 0.787897\n",
      "[678]\ttraining's auc: 0.795252\tvalid_1's auc: 0.787897\n",
      "[679]\ttraining's auc: 0.795259\tvalid_1's auc: 0.787897\n",
      "[680]\ttraining's auc: 0.795261\tvalid_1's auc: 0.787898\n",
      "[681]\ttraining's auc: 0.795269\tvalid_1's auc: 0.787899\n",
      "[682]\ttraining's auc: 0.795276\tvalid_1's auc: 0.787899\n",
      "[683]\ttraining's auc: 0.795284\tvalid_1's auc: 0.787901\n",
      "[684]\ttraining's auc: 0.795293\tvalid_1's auc: 0.787902\n",
      "[685]\ttraining's auc: 0.795307\tvalid_1's auc: 0.787905\n",
      "[686]\ttraining's auc: 0.795318\tvalid_1's auc: 0.78791\n",
      "[687]\ttraining's auc: 0.79533\tvalid_1's auc: 0.787913\n",
      "[688]\ttraining's auc: 0.795337\tvalid_1's auc: 0.787919\n",
      "[689]\ttraining's auc: 0.79534\tvalid_1's auc: 0.787921\n",
      "[690]\ttraining's auc: 0.795351\tvalid_1's auc: 0.78792\n",
      "[691]\ttraining's auc: 0.79536\tvalid_1's auc: 0.787926\n",
      "[692]\ttraining's auc: 0.795369\tvalid_1's auc: 0.787927\n",
      "[693]\ttraining's auc: 0.795375\tvalid_1's auc: 0.787931\n",
      "[694]\ttraining's auc: 0.795377\tvalid_1's auc: 0.787932\n",
      "[695]\ttraining's auc: 0.79538\tvalid_1's auc: 0.787933\n",
      "[696]\ttraining's auc: 0.795384\tvalid_1's auc: 0.787935\n",
      "[697]\ttraining's auc: 0.795393\tvalid_1's auc: 0.787936\n",
      "[698]\ttraining's auc: 0.795399\tvalid_1's auc: 0.787941\n",
      "[699]\ttraining's auc: 0.795403\tvalid_1's auc: 0.787944\n",
      "[700]\ttraining's auc: 0.795425\tvalid_1's auc: 0.787947\n",
      "[701]\ttraining's auc: 0.795429\tvalid_1's auc: 0.787947\n",
      "[702]\ttraining's auc: 0.79544\tvalid_1's auc: 0.787947\n",
      "[703]\ttraining's auc: 0.795448\tvalid_1's auc: 0.787951\n",
      "[704]\ttraining's auc: 0.79545\tvalid_1's auc: 0.78795\n",
      "[705]\ttraining's auc: 0.795453\tvalid_1's auc: 0.78795\n",
      "[706]\ttraining's auc: 0.795463\tvalid_1's auc: 0.78795\n",
      "[707]\ttraining's auc: 0.795479\tvalid_1's auc: 0.787957\n",
      "[708]\ttraining's auc: 0.795489\tvalid_1's auc: 0.787958\n",
      "[709]\ttraining's auc: 0.795494\tvalid_1's auc: 0.787958\n",
      "[710]\ttraining's auc: 0.795496\tvalid_1's auc: 0.787958\n",
      "[711]\ttraining's auc: 0.795498\tvalid_1's auc: 0.787958\n",
      "[712]\ttraining's auc: 0.795504\tvalid_1's auc: 0.787964\n",
      "[713]\ttraining's auc: 0.795514\tvalid_1's auc: 0.787967\n",
      "[714]\ttraining's auc: 0.795524\tvalid_1's auc: 0.78797\n",
      "[715]\ttraining's auc: 0.79553\tvalid_1's auc: 0.78797\n",
      "[716]\ttraining's auc: 0.79554\tvalid_1's auc: 0.787972\n",
      "[717]\ttraining's auc: 0.795542\tvalid_1's auc: 0.787972\n",
      "[718]\ttraining's auc: 0.795548\tvalid_1's auc: 0.787974\n",
      "[719]\ttraining's auc: 0.795558\tvalid_1's auc: 0.787975\n",
      "[720]\ttraining's auc: 0.795562\tvalid_1's auc: 0.787974\n",
      "[721]\ttraining's auc: 0.795564\tvalid_1's auc: 0.787974\n",
      "[722]\ttraining's auc: 0.795573\tvalid_1's auc: 0.787978\n",
      "[723]\ttraining's auc: 0.795575\tvalid_1's auc: 0.787978\n",
      "[724]\ttraining's auc: 0.795586\tvalid_1's auc: 0.787981\n",
      "[725]\ttraining's auc: 0.795601\tvalid_1's auc: 0.787983\n",
      "[726]\ttraining's auc: 0.795607\tvalid_1's auc: 0.787983\n",
      "[727]\ttraining's auc: 0.795612\tvalid_1's auc: 0.787986\n",
      "[728]\ttraining's auc: 0.795616\tvalid_1's auc: 0.787986\n",
      "[729]\ttraining's auc: 0.79562\tvalid_1's auc: 0.787986\n",
      "[730]\ttraining's auc: 0.795632\tvalid_1's auc: 0.787986\n",
      "[731]\ttraining's auc: 0.795634\tvalid_1's auc: 0.787987\n",
      "[732]\ttraining's auc: 0.795641\tvalid_1's auc: 0.787988\n",
      "[733]\ttraining's auc: 0.795645\tvalid_1's auc: 0.787988\n",
      "[734]\ttraining's auc: 0.795653\tvalid_1's auc: 0.78799\n",
      "[735]\ttraining's auc: 0.795663\tvalid_1's auc: 0.787997\n",
      "[736]\ttraining's auc: 0.795664\tvalid_1's auc: 0.787997\n",
      "[737]\ttraining's auc: 0.795673\tvalid_1's auc: 0.787996\n",
      "[738]\ttraining's auc: 0.795685\tvalid_1's auc: 0.788001\n",
      "[739]\ttraining's auc: 0.795695\tvalid_1's auc: 0.788004\n",
      "[740]\ttraining's auc: 0.795715\tvalid_1's auc: 0.788005\n",
      "[741]\ttraining's auc: 0.795717\tvalid_1's auc: 0.788006\n",
      "[742]\ttraining's auc: 0.795731\tvalid_1's auc: 0.78801\n",
      "[743]\ttraining's auc: 0.795742\tvalid_1's auc: 0.788013\n",
      "[744]\ttraining's auc: 0.795746\tvalid_1's auc: 0.788015\n",
      "[745]\ttraining's auc: 0.795752\tvalid_1's auc: 0.788016\n",
      "[746]\ttraining's auc: 0.795762\tvalid_1's auc: 0.78802\n",
      "[747]\ttraining's auc: 0.795775\tvalid_1's auc: 0.788021\n",
      "[748]\ttraining's auc: 0.795778\tvalid_1's auc: 0.788022\n",
      "[749]\ttraining's auc: 0.795786\tvalid_1's auc: 0.788028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttraining's auc: 0.795788\tvalid_1's auc: 0.788028\n",
      "[751]\ttraining's auc: 0.795795\tvalid_1's auc: 0.788028\n",
      "[752]\ttraining's auc: 0.795803\tvalid_1's auc: 0.788035\n",
      "[753]\ttraining's auc: 0.795807\tvalid_1's auc: 0.788036\n",
      "[754]\ttraining's auc: 0.795811\tvalid_1's auc: 0.788035\n",
      "[755]\ttraining's auc: 0.795824\tvalid_1's auc: 0.788039\n",
      "[756]\ttraining's auc: 0.795829\tvalid_1's auc: 0.788038\n",
      "[757]\ttraining's auc: 0.795832\tvalid_1's auc: 0.788038\n",
      "[758]\ttraining's auc: 0.795836\tvalid_1's auc: 0.78804\n",
      "[759]\ttraining's auc: 0.795844\tvalid_1's auc: 0.78804\n",
      "[760]\ttraining's auc: 0.795848\tvalid_1's auc: 0.78804\n",
      "[761]\ttraining's auc: 0.795854\tvalid_1's auc: 0.788041\n",
      "[762]\ttraining's auc: 0.795866\tvalid_1's auc: 0.788043\n",
      "[763]\ttraining's auc: 0.795867\tvalid_1's auc: 0.788044\n",
      "[764]\ttraining's auc: 0.795871\tvalid_1's auc: 0.788045\n",
      "[765]\ttraining's auc: 0.795884\tvalid_1's auc: 0.788051\n",
      "[766]\ttraining's auc: 0.79589\tvalid_1's auc: 0.788057\n",
      "[767]\ttraining's auc: 0.795895\tvalid_1's auc: 0.788062\n",
      "[768]\ttraining's auc: 0.795907\tvalid_1's auc: 0.788062\n",
      "[769]\ttraining's auc: 0.795912\tvalid_1's auc: 0.788064\n",
      "[770]\ttraining's auc: 0.795915\tvalid_1's auc: 0.788064\n",
      "[771]\ttraining's auc: 0.795916\tvalid_1's auc: 0.788064\n",
      "[772]\ttraining's auc: 0.795928\tvalid_1's auc: 0.788065\n",
      "[773]\ttraining's auc: 0.795931\tvalid_1's auc: 0.788067\n",
      "[774]\ttraining's auc: 0.795939\tvalid_1's auc: 0.788071\n",
      "[775]\ttraining's auc: 0.795946\tvalid_1's auc: 0.788069\n",
      "[776]\ttraining's auc: 0.795954\tvalid_1's auc: 0.788076\n",
      "[777]\ttraining's auc: 0.795959\tvalid_1's auc: 0.788076\n",
      "[778]\ttraining's auc: 0.795972\tvalid_1's auc: 0.788078\n",
      "[779]\ttraining's auc: 0.79598\tvalid_1's auc: 0.788079\n",
      "[780]\ttraining's auc: 0.795996\tvalid_1's auc: 0.788084\n",
      "[781]\ttraining's auc: 0.795998\tvalid_1's auc: 0.788084\n",
      "[782]\ttraining's auc: 0.796009\tvalid_1's auc: 0.788095\n",
      "[783]\ttraining's auc: 0.796018\tvalid_1's auc: 0.788096\n",
      "[784]\ttraining's auc: 0.796021\tvalid_1's auc: 0.788096\n",
      "[785]\ttraining's auc: 0.796029\tvalid_1's auc: 0.788096\n",
      "[786]\ttraining's auc: 0.796041\tvalid_1's auc: 0.788099\n",
      "[787]\ttraining's auc: 0.796047\tvalid_1's auc: 0.788098\n",
      "[788]\ttraining's auc: 0.79605\tvalid_1's auc: 0.788101\n",
      "[789]\ttraining's auc: 0.796066\tvalid_1's auc: 0.788105\n",
      "[790]\ttraining's auc: 0.796072\tvalid_1's auc: 0.788105\n",
      "[791]\ttraining's auc: 0.796075\tvalid_1's auc: 0.788106\n",
      "[792]\ttraining's auc: 0.796077\tvalid_1's auc: 0.788106\n",
      "[793]\ttraining's auc: 0.79608\tvalid_1's auc: 0.788107\n",
      "[794]\ttraining's auc: 0.796083\tvalid_1's auc: 0.788107\n",
      "[795]\ttraining's auc: 0.796084\tvalid_1's auc: 0.788107\n",
      "[796]\ttraining's auc: 0.796087\tvalid_1's auc: 0.788106\n",
      "[797]\ttraining's auc: 0.796093\tvalid_1's auc: 0.788106\n",
      "[798]\ttraining's auc: 0.796111\tvalid_1's auc: 0.788107\n",
      "[799]\ttraining's auc: 0.796116\tvalid_1's auc: 0.788109\n",
      "[800]\ttraining's auc: 0.79612\tvalid_1's auc: 0.788109\n",
      "[801]\ttraining's auc: 0.796122\tvalid_1's auc: 0.78811\n",
      "[802]\ttraining's auc: 0.796125\tvalid_1's auc: 0.788109\n",
      "[803]\ttraining's auc: 0.79613\tvalid_1's auc: 0.788113\n",
      "[804]\ttraining's auc: 0.796132\tvalid_1's auc: 0.788113\n",
      "[805]\ttraining's auc: 0.796138\tvalid_1's auc: 0.788118\n",
      "[806]\ttraining's auc: 0.79614\tvalid_1's auc: 0.788119\n",
      "[807]\ttraining's auc: 0.796152\tvalid_1's auc: 0.788122\n",
      "[808]\ttraining's auc: 0.796172\tvalid_1's auc: 0.788124\n",
      "[809]\ttraining's auc: 0.796174\tvalid_1's auc: 0.788124\n",
      "[810]\ttraining's auc: 0.796185\tvalid_1's auc: 0.788128\n",
      "[811]\ttraining's auc: 0.796187\tvalid_1's auc: 0.788129\n",
      "[812]\ttraining's auc: 0.79619\tvalid_1's auc: 0.78813\n",
      "[813]\ttraining's auc: 0.796195\tvalid_1's auc: 0.788129\n",
      "[814]\ttraining's auc: 0.796203\tvalid_1's auc: 0.788136\n",
      "[815]\ttraining's auc: 0.796206\tvalid_1's auc: 0.788135\n",
      "[816]\ttraining's auc: 0.796208\tvalid_1's auc: 0.788135\n",
      "[817]\ttraining's auc: 0.79622\tvalid_1's auc: 0.788137\n",
      "[818]\ttraining's auc: 0.796222\tvalid_1's auc: 0.788137\n",
      "[819]\ttraining's auc: 0.796227\tvalid_1's auc: 0.788139\n",
      "[820]\ttraining's auc: 0.796236\tvalid_1's auc: 0.788141\n",
      "[821]\ttraining's auc: 0.79624\tvalid_1's auc: 0.788145\n",
      "[822]\ttraining's auc: 0.796254\tvalid_1's auc: 0.788148\n",
      "[823]\ttraining's auc: 0.796257\tvalid_1's auc: 0.788148\n",
      "[824]\ttraining's auc: 0.79626\tvalid_1's auc: 0.788148\n",
      "[825]\ttraining's auc: 0.796275\tvalid_1's auc: 0.788156\n",
      "[826]\ttraining's auc: 0.796288\tvalid_1's auc: 0.788158\n",
      "[827]\ttraining's auc: 0.79629\tvalid_1's auc: 0.788158\n",
      "[828]\ttraining's auc: 0.796292\tvalid_1's auc: 0.788158\n",
      "[829]\ttraining's auc: 0.796298\tvalid_1's auc: 0.788158\n",
      "[830]\ttraining's auc: 0.796306\tvalid_1's auc: 0.788159\n",
      "[831]\ttraining's auc: 0.796308\tvalid_1's auc: 0.788159\n",
      "[832]\ttraining's auc: 0.796309\tvalid_1's auc: 0.788159\n",
      "[833]\ttraining's auc: 0.796314\tvalid_1's auc: 0.788159\n",
      "[834]\ttraining's auc: 0.796316\tvalid_1's auc: 0.788159\n",
      "[835]\ttraining's auc: 0.796317\tvalid_1's auc: 0.788159\n",
      "[836]\ttraining's auc: 0.796323\tvalid_1's auc: 0.788158\n",
      "[837]\ttraining's auc: 0.796327\tvalid_1's auc: 0.788161\n",
      "[838]\ttraining's auc: 0.796338\tvalid_1's auc: 0.788162\n",
      "[839]\ttraining's auc: 0.796341\tvalid_1's auc: 0.788162\n",
      "[840]\ttraining's auc: 0.796348\tvalid_1's auc: 0.788169\n",
      "[841]\ttraining's auc: 0.796358\tvalid_1's auc: 0.78817\n",
      "[842]\ttraining's auc: 0.796361\tvalid_1's auc: 0.78817\n",
      "[843]\ttraining's auc: 0.796363\tvalid_1's auc: 0.78817\n",
      "[844]\ttraining's auc: 0.796364\tvalid_1's auc: 0.78817\n",
      "[845]\ttraining's auc: 0.796366\tvalid_1's auc: 0.788171\n",
      "[846]\ttraining's auc: 0.796386\tvalid_1's auc: 0.788173\n",
      "[847]\ttraining's auc: 0.796391\tvalid_1's auc: 0.788172\n",
      "[848]\ttraining's auc: 0.796401\tvalid_1's auc: 0.788174\n",
      "[849]\ttraining's auc: 0.796403\tvalid_1's auc: 0.788174\n",
      "[850]\ttraining's auc: 0.796406\tvalid_1's auc: 0.788176\n",
      "[851]\ttraining's auc: 0.796419\tvalid_1's auc: 0.788178\n",
      "[852]\ttraining's auc: 0.796426\tvalid_1's auc: 0.788184\n",
      "[853]\ttraining's auc: 0.796436\tvalid_1's auc: 0.788187\n",
      "[854]\ttraining's auc: 0.79645\tvalid_1's auc: 0.788191\n",
      "[855]\ttraining's auc: 0.796462\tvalid_1's auc: 0.788193\n",
      "[856]\ttraining's auc: 0.796464\tvalid_1's auc: 0.788194\n",
      "[857]\ttraining's auc: 0.79647\tvalid_1's auc: 0.788198\n",
      "[858]\ttraining's auc: 0.796472\tvalid_1's auc: 0.788199\n",
      "[859]\ttraining's auc: 0.796484\tvalid_1's auc: 0.788203\n",
      "[860]\ttraining's auc: 0.796494\tvalid_1's auc: 0.788204\n",
      "[861]\ttraining's auc: 0.796506\tvalid_1's auc: 0.788204\n",
      "[862]\ttraining's auc: 0.796508\tvalid_1's auc: 0.788205\n",
      "[863]\ttraining's auc: 0.796517\tvalid_1's auc: 0.788207\n",
      "[864]\ttraining's auc: 0.79652\tvalid_1's auc: 0.788207\n",
      "[865]\ttraining's auc: 0.796526\tvalid_1's auc: 0.788207\n",
      "[866]\ttraining's auc: 0.796528\tvalid_1's auc: 0.788207\n",
      "[867]\ttraining's auc: 0.796536\tvalid_1's auc: 0.788206\n",
      "[868]\ttraining's auc: 0.796538\tvalid_1's auc: 0.788206\n",
      "[869]\ttraining's auc: 0.796543\tvalid_1's auc: 0.788207\n",
      "[870]\ttraining's auc: 0.796552\tvalid_1's auc: 0.788217\n",
      "[871]\ttraining's auc: 0.796559\tvalid_1's auc: 0.788217\n",
      "[872]\ttraining's auc: 0.796562\tvalid_1's auc: 0.788216\n",
      "[873]\ttraining's auc: 0.796572\tvalid_1's auc: 0.788221\n",
      "[874]\ttraining's auc: 0.796574\tvalid_1's auc: 0.788222\n",
      "[875]\ttraining's auc: 0.796578\tvalid_1's auc: 0.788224\n",
      "[876]\ttraining's auc: 0.79658\tvalid_1's auc: 0.788224\n",
      "[877]\ttraining's auc: 0.796584\tvalid_1's auc: 0.788224\n",
      "[878]\ttraining's auc: 0.796586\tvalid_1's auc: 0.788225\n",
      "[879]\ttraining's auc: 0.796587\tvalid_1's auc: 0.788225\n",
      "[880]\ttraining's auc: 0.796591\tvalid_1's auc: 0.788226\n",
      "[881]\ttraining's auc: 0.796603\tvalid_1's auc: 0.788229\n",
      "[882]\ttraining's auc: 0.796605\tvalid_1's auc: 0.78823\n",
      "[883]\ttraining's auc: 0.79661\tvalid_1's auc: 0.78823\n",
      "[884]\ttraining's auc: 0.796612\tvalid_1's auc: 0.78823\n",
      "[885]\ttraining's auc: 0.796616\tvalid_1's auc: 0.788233\n",
      "[886]\ttraining's auc: 0.796625\tvalid_1's auc: 0.788233\n",
      "[887]\ttraining's auc: 0.796635\tvalid_1's auc: 0.788233\n",
      "[888]\ttraining's auc: 0.796646\tvalid_1's auc: 0.788236\n",
      "[889]\ttraining's auc: 0.796649\tvalid_1's auc: 0.788237\n",
      "[890]\ttraining's auc: 0.796651\tvalid_1's auc: 0.788237\n",
      "[891]\ttraining's auc: 0.796653\tvalid_1's auc: 0.788236\n",
      "[892]\ttraining's auc: 0.79666\tvalid_1's auc: 0.788243\n",
      "[893]\ttraining's auc: 0.796666\tvalid_1's auc: 0.788246\n",
      "[894]\ttraining's auc: 0.796667\tvalid_1's auc: 0.788246\n",
      "[895]\ttraining's auc: 0.796678\tvalid_1's auc: 0.788248\n",
      "[896]\ttraining's auc: 0.796681\tvalid_1's auc: 0.78825\n",
      "[897]\ttraining's auc: 0.796692\tvalid_1's auc: 0.788253\n",
      "[898]\ttraining's auc: 0.796697\tvalid_1's auc: 0.788254\n",
      "[899]\ttraining's auc: 0.796706\tvalid_1's auc: 0.788255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's auc: 0.796717\tvalid_1's auc: 0.788255\n",
      "[901]\ttraining's auc: 0.796719\tvalid_1's auc: 0.788255\n",
      "[902]\ttraining's auc: 0.796728\tvalid_1's auc: 0.788255\n",
      "[903]\ttraining's auc: 0.796732\tvalid_1's auc: 0.788255\n",
      "[904]\ttraining's auc: 0.796734\tvalid_1's auc: 0.788255\n",
      "[905]\ttraining's auc: 0.796736\tvalid_1's auc: 0.788255\n",
      "[906]\ttraining's auc: 0.796746\tvalid_1's auc: 0.788255\n",
      "[907]\ttraining's auc: 0.79675\tvalid_1's auc: 0.788258\n",
      "[908]\ttraining's auc: 0.796752\tvalid_1's auc: 0.788258\n",
      "[909]\ttraining's auc: 0.796759\tvalid_1's auc: 0.788259\n",
      "[910]\ttraining's auc: 0.796765\tvalid_1's auc: 0.788258\n",
      "[911]\ttraining's auc: 0.796766\tvalid_1's auc: 0.788258\n",
      "[912]\ttraining's auc: 0.796768\tvalid_1's auc: 0.788259\n",
      "[913]\ttraining's auc: 0.796773\tvalid_1's auc: 0.788258\n",
      "[914]\ttraining's auc: 0.796776\tvalid_1's auc: 0.788258\n",
      "[915]\ttraining's auc: 0.796787\tvalid_1's auc: 0.788262\n",
      "[916]\ttraining's auc: 0.79679\tvalid_1's auc: 0.788262\n",
      "[917]\ttraining's auc: 0.796797\tvalid_1's auc: 0.788268\n",
      "[918]\ttraining's auc: 0.7968\tvalid_1's auc: 0.788268\n",
      "[919]\ttraining's auc: 0.796802\tvalid_1's auc: 0.788268\n",
      "[920]\ttraining's auc: 0.796806\tvalid_1's auc: 0.788268\n",
      "[921]\ttraining's auc: 0.796808\tvalid_1's auc: 0.788268\n",
      "[922]\ttraining's auc: 0.79681\tvalid_1's auc: 0.788268\n",
      "[923]\ttraining's auc: 0.796811\tvalid_1's auc: 0.788268\n",
      "[924]\ttraining's auc: 0.796813\tvalid_1's auc: 0.788268\n",
      "[925]\ttraining's auc: 0.796822\tvalid_1's auc: 0.788268\n",
      "[926]\ttraining's auc: 0.796824\tvalid_1's auc: 0.788268\n",
      "[927]\ttraining's auc: 0.796828\tvalid_1's auc: 0.788268\n",
      "[928]\ttraining's auc: 0.796831\tvalid_1's auc: 0.78827\n",
      "[929]\ttraining's auc: 0.796842\tvalid_1's auc: 0.788275\n",
      "[930]\ttraining's auc: 0.796843\tvalid_1's auc: 0.788275\n",
      "[931]\ttraining's auc: 0.796845\tvalid_1's auc: 0.788275\n",
      "[932]\ttraining's auc: 0.796859\tvalid_1's auc: 0.788277\n",
      "[933]\ttraining's auc: 0.796865\tvalid_1's auc: 0.788277\n",
      "[934]\ttraining's auc: 0.796868\tvalid_1's auc: 0.788279\n",
      "[935]\ttraining's auc: 0.796871\tvalid_1's auc: 0.788278\n",
      "[936]\ttraining's auc: 0.796882\tvalid_1's auc: 0.788278\n",
      "[937]\ttraining's auc: 0.796886\tvalid_1's auc: 0.788278\n",
      "[938]\ttraining's auc: 0.79689\tvalid_1's auc: 0.788281\n",
      "[939]\ttraining's auc: 0.796892\tvalid_1's auc: 0.788281\n",
      "[940]\ttraining's auc: 0.796893\tvalid_1's auc: 0.788281\n",
      "[941]\ttraining's auc: 0.796897\tvalid_1's auc: 0.78828\n",
      "[942]\ttraining's auc: 0.79691\tvalid_1's auc: 0.788282\n",
      "[943]\ttraining's auc: 0.796913\tvalid_1's auc: 0.788283\n",
      "[944]\ttraining's auc: 0.796927\tvalid_1's auc: 0.788287\n",
      "[945]\ttraining's auc: 0.796929\tvalid_1's auc: 0.788286\n",
      "[946]\ttraining's auc: 0.79693\tvalid_1's auc: 0.788286\n",
      "[947]\ttraining's auc: 0.796936\tvalid_1's auc: 0.78829\n",
      "[948]\ttraining's auc: 0.796942\tvalid_1's auc: 0.788289\n",
      "[949]\ttraining's auc: 0.796955\tvalid_1's auc: 0.788292\n",
      "[950]\ttraining's auc: 0.796959\tvalid_1's auc: 0.788294\n",
      "[951]\ttraining's auc: 0.796968\tvalid_1's auc: 0.788296\n",
      "[952]\ttraining's auc: 0.796974\tvalid_1's auc: 0.788302\n",
      "[953]\ttraining's auc: 0.796977\tvalid_1's auc: 0.788302\n",
      "[954]\ttraining's auc: 0.79698\tvalid_1's auc: 0.788303\n",
      "[955]\ttraining's auc: 0.796984\tvalid_1's auc: 0.788305\n",
      "[956]\ttraining's auc: 0.796986\tvalid_1's auc: 0.788305\n",
      "[957]\ttraining's auc: 0.796996\tvalid_1's auc: 0.788306\n",
      "[958]\ttraining's auc: 0.796998\tvalid_1's auc: 0.788306\n",
      "[959]\ttraining's auc: 0.797006\tvalid_1's auc: 0.788307\n",
      "[960]\ttraining's auc: 0.797008\tvalid_1's auc: 0.788307\n",
      "[961]\ttraining's auc: 0.797013\tvalid_1's auc: 0.788311\n",
      "[962]\ttraining's auc: 0.797014\tvalid_1's auc: 0.788311\n",
      "[963]\ttraining's auc: 0.797021\tvalid_1's auc: 0.788317\n",
      "[964]\ttraining's auc: 0.797035\tvalid_1's auc: 0.788316\n",
      "[965]\ttraining's auc: 0.797043\tvalid_1's auc: 0.788324\n",
      "[966]\ttraining's auc: 0.797044\tvalid_1's auc: 0.788324\n",
      "[967]\ttraining's auc: 0.797052\tvalid_1's auc: 0.788324\n",
      "[968]\ttraining's auc: 0.797054\tvalid_1's auc: 0.788325\n",
      "[969]\ttraining's auc: 0.79706\tvalid_1's auc: 0.788325\n",
      "[970]\ttraining's auc: 0.797069\tvalid_1's auc: 0.788324\n",
      "[971]\ttraining's auc: 0.797072\tvalid_1's auc: 0.788324\n",
      "[972]\ttraining's auc: 0.797082\tvalid_1's auc: 0.788334\n",
      "[973]\ttraining's auc: 0.797089\tvalid_1's auc: 0.788339\n",
      "[974]\ttraining's auc: 0.797095\tvalid_1's auc: 0.788339\n",
      "[975]\ttraining's auc: 0.797106\tvalid_1's auc: 0.788339\n",
      "[976]\ttraining's auc: 0.797108\tvalid_1's auc: 0.78834\n",
      "[977]\ttraining's auc: 0.797113\tvalid_1's auc: 0.788344\n",
      "[978]\ttraining's auc: 0.797121\tvalid_1's auc: 0.788344\n",
      "[979]\ttraining's auc: 0.797126\tvalid_1's auc: 0.788345\n",
      "[980]\ttraining's auc: 0.79714\tvalid_1's auc: 0.788348\n",
      "[981]\ttraining's auc: 0.797142\tvalid_1's auc: 0.788348\n",
      "[982]\ttraining's auc: 0.797143\tvalid_1's auc: 0.788348\n",
      "[983]\ttraining's auc: 0.797145\tvalid_1's auc: 0.788348\n",
      "[984]\ttraining's auc: 0.79715\tvalid_1's auc: 0.78835\n",
      "[985]\ttraining's auc: 0.797158\tvalid_1's auc: 0.78835\n",
      "[986]\ttraining's auc: 0.79716\tvalid_1's auc: 0.78835\n",
      "[987]\ttraining's auc: 0.797162\tvalid_1's auc: 0.78835\n",
      "[988]\ttraining's auc: 0.797163\tvalid_1's auc: 0.78835\n",
      "[989]\ttraining's auc: 0.797165\tvalid_1's auc: 0.78835\n",
      "[990]\ttraining's auc: 0.797168\tvalid_1's auc: 0.78835\n",
      "[991]\ttraining's auc: 0.797174\tvalid_1's auc: 0.788349\n",
      "[992]\ttraining's auc: 0.797175\tvalid_1's auc: 0.788349\n",
      "[993]\ttraining's auc: 0.797188\tvalid_1's auc: 0.788349\n",
      "[994]\ttraining's auc: 0.797189\tvalid_1's auc: 0.78835\n",
      "[995]\ttraining's auc: 0.797196\tvalid_1's auc: 0.788349\n",
      "[996]\ttraining's auc: 0.797198\tvalid_1's auc: 0.788349\n",
      "[997]\ttraining's auc: 0.7972\tvalid_1's auc: 0.788349\n",
      "[998]\ttraining's auc: 0.797205\tvalid_1's auc: 0.788348\n",
      "[999]\ttraining's auc: 0.797211\tvalid_1's auc: 0.788353\n",
      "[1000]\ttraining's auc: 0.79722\tvalid_1's auc: 0.788353\n",
      "[1001]\ttraining's auc: 0.797227\tvalid_1's auc: 0.788353\n",
      "[1002]\ttraining's auc: 0.797231\tvalid_1's auc: 0.788355\n",
      "[1003]\ttraining's auc: 0.797232\tvalid_1's auc: 0.788355\n",
      "[1004]\ttraining's auc: 0.797236\tvalid_1's auc: 0.788354\n",
      "[1005]\ttraining's auc: 0.797237\tvalid_1's auc: 0.788354\n",
      "[1006]\ttraining's auc: 0.797244\tvalid_1's auc: 0.788353\n",
      "[1007]\ttraining's auc: 0.797246\tvalid_1's auc: 0.788354\n",
      "[1008]\ttraining's auc: 0.797248\tvalid_1's auc: 0.788354\n",
      "[1009]\ttraining's auc: 0.797253\tvalid_1's auc: 0.788359\n",
      "[1010]\ttraining's auc: 0.797255\tvalid_1's auc: 0.788359\n",
      "[1011]\ttraining's auc: 0.797259\tvalid_1's auc: 0.788364\n",
      "[1012]\ttraining's auc: 0.797261\tvalid_1's auc: 0.788364\n",
      "[1013]\ttraining's auc: 0.797266\tvalid_1's auc: 0.788363\n",
      "[1014]\ttraining's auc: 0.797269\tvalid_1's auc: 0.788363\n",
      "[1015]\ttraining's auc: 0.797271\tvalid_1's auc: 0.788363\n",
      "[1016]\ttraining's auc: 0.797272\tvalid_1's auc: 0.788363\n",
      "[1017]\ttraining's auc: 0.797275\tvalid_1's auc: 0.788362\n",
      "[1018]\ttraining's auc: 0.797277\tvalid_1's auc: 0.788362\n",
      "[1019]\ttraining's auc: 0.797278\tvalid_1's auc: 0.788362\n",
      "[1020]\ttraining's auc: 0.79728\tvalid_1's auc: 0.788362\n",
      "[1021]\ttraining's auc: 0.797281\tvalid_1's auc: 0.788362\n",
      "[1022]\ttraining's auc: 0.797283\tvalid_1's auc: 0.788362\n",
      "[1023]\ttraining's auc: 0.797284\tvalid_1's auc: 0.788362\n",
      "[1024]\ttraining's auc: 0.79729\tvalid_1's auc: 0.788363\n",
      "[1025]\ttraining's auc: 0.797303\tvalid_1's auc: 0.788365\n",
      "[1026]\ttraining's auc: 0.797311\tvalid_1's auc: 0.788373\n",
      "[1027]\ttraining's auc: 0.797315\tvalid_1's auc: 0.788373\n",
      "[1028]\ttraining's auc: 0.797321\tvalid_1's auc: 0.788376\n",
      "[1029]\ttraining's auc: 0.797324\tvalid_1's auc: 0.788375\n",
      "[1030]\ttraining's auc: 0.797327\tvalid_1's auc: 0.788377\n",
      "[1031]\ttraining's auc: 0.797328\tvalid_1's auc: 0.788377\n",
      "[1032]\ttraining's auc: 0.797333\tvalid_1's auc: 0.788381\n",
      "[1033]\ttraining's auc: 0.797335\tvalid_1's auc: 0.788381\n",
      "[1034]\ttraining's auc: 0.797337\tvalid_1's auc: 0.788381\n",
      "[1035]\ttraining's auc: 0.797341\tvalid_1's auc: 0.788381\n",
      "[1036]\ttraining's auc: 0.797343\tvalid_1's auc: 0.788382\n",
      "[1037]\ttraining's auc: 0.797344\tvalid_1's auc: 0.788382\n",
      "[1038]\ttraining's auc: 0.797348\tvalid_1's auc: 0.788381\n",
      "[1039]\ttraining's auc: 0.79735\tvalid_1's auc: 0.788382\n",
      "[1040]\ttraining's auc: 0.797355\tvalid_1's auc: 0.788381\n",
      "[1041]\ttraining's auc: 0.797358\tvalid_1's auc: 0.788382\n",
      "[1042]\ttraining's auc: 0.797368\tvalid_1's auc: 0.788384\n",
      "[1043]\ttraining's auc: 0.797371\tvalid_1's auc: 0.788384\n",
      "[1044]\ttraining's auc: 0.797381\tvalid_1's auc: 0.788386\n",
      "[1045]\ttraining's auc: 0.797382\tvalid_1's auc: 0.788386\n",
      "[1046]\ttraining's auc: 0.797383\tvalid_1's auc: 0.788386\n",
      "[1047]\ttraining's auc: 0.797385\tvalid_1's auc: 0.788386\n",
      "[1048]\ttraining's auc: 0.797395\tvalid_1's auc: 0.788387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1049]\ttraining's auc: 0.797396\tvalid_1's auc: 0.788387\n",
      "[1050]\ttraining's auc: 0.797397\tvalid_1's auc: 0.788387\n",
      "[1051]\ttraining's auc: 0.797401\tvalid_1's auc: 0.788389\n",
      "[1052]\ttraining's auc: 0.797403\tvalid_1's auc: 0.788389\n",
      "[1053]\ttraining's auc: 0.797404\tvalid_1's auc: 0.78839\n",
      "[1054]\ttraining's auc: 0.797409\tvalid_1's auc: 0.788394\n",
      "[1055]\ttraining's auc: 0.797425\tvalid_1's auc: 0.788394\n",
      "[1056]\ttraining's auc: 0.797431\tvalid_1's auc: 0.788394\n",
      "[1057]\ttraining's auc: 0.797432\tvalid_1's auc: 0.788393\n",
      "[1058]\ttraining's auc: 0.797443\tvalid_1's auc: 0.788396\n",
      "[1059]\ttraining's auc: 0.797445\tvalid_1's auc: 0.788396\n",
      "[1060]\ttraining's auc: 0.797455\tvalid_1's auc: 0.788398\n",
      "[1061]\ttraining's auc: 0.797462\tvalid_1's auc: 0.788398\n",
      "[1062]\ttraining's auc: 0.797469\tvalid_1's auc: 0.788398\n",
      "[1063]\ttraining's auc: 0.797471\tvalid_1's auc: 0.788398\n",
      "[1064]\ttraining's auc: 0.797474\tvalid_1's auc: 0.788397\n",
      "[1065]\ttraining's auc: 0.797482\tvalid_1's auc: 0.788397\n",
      "[1066]\ttraining's auc: 0.797491\tvalid_1's auc: 0.788397\n",
      "[1067]\ttraining's auc: 0.797492\tvalid_1's auc: 0.788397\n",
      "[1068]\ttraining's auc: 0.797494\tvalid_1's auc: 0.788397\n",
      "[1069]\ttraining's auc: 0.797495\tvalid_1's auc: 0.788397\n",
      "[1070]\ttraining's auc: 0.797504\tvalid_1's auc: 0.788402\n",
      "[1071]\ttraining's auc: 0.797505\tvalid_1's auc: 0.788402\n",
      "[1072]\ttraining's auc: 0.797508\tvalid_1's auc: 0.788403\n",
      "[1073]\ttraining's auc: 0.79751\tvalid_1's auc: 0.788402\n",
      "[1074]\ttraining's auc: 0.797513\tvalid_1's auc: 0.788402\n",
      "[1075]\ttraining's auc: 0.797515\tvalid_1's auc: 0.788403\n",
      "[1076]\ttraining's auc: 0.797519\tvalid_1's auc: 0.788402\n",
      "[1077]\ttraining's auc: 0.797521\tvalid_1's auc: 0.788402\n",
      "[1078]\ttraining's auc: 0.797528\tvalid_1's auc: 0.788402\n",
      "[1079]\ttraining's auc: 0.797531\tvalid_1's auc: 0.788402\n",
      "[1080]\ttraining's auc: 0.797536\tvalid_1's auc: 0.788401\n",
      "[1081]\ttraining's auc: 0.797538\tvalid_1's auc: 0.788401\n",
      "[1082]\ttraining's auc: 0.797539\tvalid_1's auc: 0.788401\n",
      "[1083]\ttraining's auc: 0.797541\tvalid_1's auc: 0.788402\n",
      "[1084]\ttraining's auc: 0.797543\tvalid_1's auc: 0.788401\n",
      "[1085]\ttraining's auc: 0.797544\tvalid_1's auc: 0.788402\n",
      "[1086]\ttraining's auc: 0.797546\tvalid_1's auc: 0.788402\n",
      "[1087]\ttraining's auc: 0.797548\tvalid_1's auc: 0.788402\n",
      "[1088]\ttraining's auc: 0.797549\tvalid_1's auc: 0.788402\n",
      "[1089]\ttraining's auc: 0.797551\tvalid_1's auc: 0.788402\n",
      "[1090]\ttraining's auc: 0.797554\tvalid_1's auc: 0.788402\n",
      "[1091]\ttraining's auc: 0.797558\tvalid_1's auc: 0.788405\n",
      "[1092]\ttraining's auc: 0.797561\tvalid_1's auc: 0.788407\n",
      "[1093]\ttraining's auc: 0.79757\tvalid_1's auc: 0.788406\n",
      "[1094]\ttraining's auc: 0.797571\tvalid_1's auc: 0.788406\n",
      "[1095]\ttraining's auc: 0.797576\tvalid_1's auc: 0.788406\n",
      "[1096]\ttraining's auc: 0.797579\tvalid_1's auc: 0.788407\n",
      "[1097]\ttraining's auc: 0.797585\tvalid_1's auc: 0.788406\n",
      "[1098]\ttraining's auc: 0.797587\tvalid_1's auc: 0.788406\n",
      "[1099]\ttraining's auc: 0.797589\tvalid_1's auc: 0.788406\n",
      "[1100]\ttraining's auc: 0.79759\tvalid_1's auc: 0.788407\n",
      "[1101]\ttraining's auc: 0.797592\tvalid_1's auc: 0.788407\n",
      "[1102]\ttraining's auc: 0.797595\tvalid_1's auc: 0.788408\n",
      "[1103]\ttraining's auc: 0.797597\tvalid_1's auc: 0.788408\n",
      "[1104]\ttraining's auc: 0.797598\tvalid_1's auc: 0.788408\n",
      "[1105]\ttraining's auc: 0.7976\tvalid_1's auc: 0.788408\n",
      "[1106]\ttraining's auc: 0.797601\tvalid_1's auc: 0.788408\n",
      "[1107]\ttraining's auc: 0.797603\tvalid_1's auc: 0.788408\n",
      "[1108]\ttraining's auc: 0.797605\tvalid_1's auc: 0.788409\n",
      "[1109]\ttraining's auc: 0.797607\tvalid_1's auc: 0.788409\n",
      "[1110]\ttraining's auc: 0.797612\tvalid_1's auc: 0.788413\n",
      "[1111]\ttraining's auc: 0.797613\tvalid_1's auc: 0.788413\n",
      "[1112]\ttraining's auc: 0.797621\tvalid_1's auc: 0.788412\n",
      "[1113]\ttraining's auc: 0.797624\tvalid_1's auc: 0.788412\n",
      "[1114]\ttraining's auc: 0.797626\tvalid_1's auc: 0.788412\n",
      "[1115]\ttraining's auc: 0.797629\tvalid_1's auc: 0.788414\n",
      "[1116]\ttraining's auc: 0.79764\tvalid_1's auc: 0.788415\n",
      "[1117]\ttraining's auc: 0.797642\tvalid_1's auc: 0.788415\n",
      "[1118]\ttraining's auc: 0.797643\tvalid_1's auc: 0.788415\n",
      "[1119]\ttraining's auc: 0.797645\tvalid_1's auc: 0.788416\n",
      "[1120]\ttraining's auc: 0.797646\tvalid_1's auc: 0.788416\n",
      "[1121]\ttraining's auc: 0.797653\tvalid_1's auc: 0.788422\n",
      "[1122]\ttraining's auc: 0.797654\tvalid_1's auc: 0.788422\n",
      "[1123]\ttraining's auc: 0.797656\tvalid_1's auc: 0.788422\n",
      "[1124]\ttraining's auc: 0.797658\tvalid_1's auc: 0.788422\n",
      "[1125]\ttraining's auc: 0.797659\tvalid_1's auc: 0.788423\n",
      "[1126]\ttraining's auc: 0.797661\tvalid_1's auc: 0.788423\n",
      "[1127]\ttraining's auc: 0.797664\tvalid_1's auc: 0.788424\n",
      "[1128]\ttraining's auc: 0.797666\tvalid_1's auc: 0.788424\n",
      "[1129]\ttraining's auc: 0.797667\tvalid_1's auc: 0.788424\n",
      "[1130]\ttraining's auc: 0.79767\tvalid_1's auc: 0.788426\n",
      "[1131]\ttraining's auc: 0.797672\tvalid_1's auc: 0.788426\n",
      "[1132]\ttraining's auc: 0.797675\tvalid_1's auc: 0.788426\n",
      "[1133]\ttraining's auc: 0.797683\tvalid_1's auc: 0.788425\n",
      "[1134]\ttraining's auc: 0.797689\tvalid_1's auc: 0.788425\n",
      "[1135]\ttraining's auc: 0.79769\tvalid_1's auc: 0.788425\n",
      "[1136]\ttraining's auc: 0.797692\tvalid_1's auc: 0.788425\n",
      "[1137]\ttraining's auc: 0.797694\tvalid_1's auc: 0.788425\n",
      "[1138]\ttraining's auc: 0.797695\tvalid_1's auc: 0.788425\n",
      "[1139]\ttraining's auc: 0.797704\tvalid_1's auc: 0.788426\n",
      "[1140]\ttraining's auc: 0.797709\tvalid_1's auc: 0.788429\n",
      "[1141]\ttraining's auc: 0.797711\tvalid_1's auc: 0.788429\n",
      "[1142]\ttraining's auc: 0.797715\tvalid_1's auc: 0.788432\n",
      "[1143]\ttraining's auc: 0.797717\tvalid_1's auc: 0.788432\n",
      "[1144]\ttraining's auc: 0.797719\tvalid_1's auc: 0.788432\n",
      "[1145]\ttraining's auc: 0.797724\tvalid_1's auc: 0.788432\n",
      "[1146]\ttraining's auc: 0.797726\tvalid_1's auc: 0.788432\n",
      "[1147]\ttraining's auc: 0.797728\tvalid_1's auc: 0.788432\n",
      "[1148]\ttraining's auc: 0.79773\tvalid_1's auc: 0.788433\n",
      "[1149]\ttraining's auc: 0.797731\tvalid_1's auc: 0.788433\n",
      "[1150]\ttraining's auc: 0.797732\tvalid_1's auc: 0.788433\n",
      "[1151]\ttraining's auc: 0.797738\tvalid_1's auc: 0.788437\n",
      "[1152]\ttraining's auc: 0.79775\tvalid_1's auc: 0.788439\n",
      "[1153]\ttraining's auc: 0.797752\tvalid_1's auc: 0.788439\n",
      "[1154]\ttraining's auc: 0.797758\tvalid_1's auc: 0.788446\n",
      "[1155]\ttraining's auc: 0.79776\tvalid_1's auc: 0.788446\n",
      "[1156]\ttraining's auc: 0.797761\tvalid_1's auc: 0.788446\n",
      "[1157]\ttraining's auc: 0.797763\tvalid_1's auc: 0.788446\n",
      "[1158]\ttraining's auc: 0.797765\tvalid_1's auc: 0.788447\n",
      "[1159]\ttraining's auc: 0.797766\tvalid_1's auc: 0.788447\n",
      "[1160]\ttraining's auc: 0.797773\tvalid_1's auc: 0.788452\n",
      "[1161]\ttraining's auc: 0.797778\tvalid_1's auc: 0.788451\n",
      "[1162]\ttraining's auc: 0.797786\tvalid_1's auc: 0.788452\n",
      "[1163]\ttraining's auc: 0.797788\tvalid_1's auc: 0.788453\n",
      "[1164]\ttraining's auc: 0.797796\tvalid_1's auc: 0.788454\n",
      "[1165]\ttraining's auc: 0.7978\tvalid_1's auc: 0.788453\n",
      "[1166]\ttraining's auc: 0.797816\tvalid_1's auc: 0.788454\n",
      "[1167]\ttraining's auc: 0.797818\tvalid_1's auc: 0.788454\n",
      "[1168]\ttraining's auc: 0.797821\tvalid_1's auc: 0.788456\n",
      "[1169]\ttraining's auc: 0.797828\tvalid_1's auc: 0.788456\n",
      "[1170]\ttraining's auc: 0.797839\tvalid_1's auc: 0.788457\n",
      "[1171]\ttraining's auc: 0.79784\tvalid_1's auc: 0.788457\n",
      "[1172]\ttraining's auc: 0.797842\tvalid_1's auc: 0.788458\n",
      "[1173]\ttraining's auc: 0.797848\tvalid_1's auc: 0.788462\n",
      "[1174]\ttraining's auc: 0.797859\tvalid_1's auc: 0.788462\n",
      "[1175]\ttraining's auc: 0.797873\tvalid_1's auc: 0.788465\n",
      "[1176]\ttraining's auc: 0.797878\tvalid_1's auc: 0.788464\n",
      "[1177]\ttraining's auc: 0.797882\tvalid_1's auc: 0.788464\n",
      "[1178]\ttraining's auc: 0.797883\tvalid_1's auc: 0.788464\n",
      "[1179]\ttraining's auc: 0.797885\tvalid_1's auc: 0.788464\n",
      "[1180]\ttraining's auc: 0.797886\tvalid_1's auc: 0.788464\n",
      "[1181]\ttraining's auc: 0.79789\tvalid_1's auc: 0.788467\n",
      "[1182]\ttraining's auc: 0.797892\tvalid_1's auc: 0.788467\n",
      "[1183]\ttraining's auc: 0.797894\tvalid_1's auc: 0.788467\n",
      "[1184]\ttraining's auc: 0.797903\tvalid_1's auc: 0.788467\n",
      "[1185]\ttraining's auc: 0.797904\tvalid_1's auc: 0.788467\n",
      "[1186]\ttraining's auc: 0.797907\tvalid_1's auc: 0.788469\n",
      "[1187]\ttraining's auc: 0.797912\tvalid_1's auc: 0.788472\n",
      "[1188]\ttraining's auc: 0.797919\tvalid_1's auc: 0.788471\n",
      "[1189]\ttraining's auc: 0.79792\tvalid_1's auc: 0.788471\n",
      "[1190]\ttraining's auc: 0.797932\tvalid_1's auc: 0.788473\n",
      "[1191]\ttraining's auc: 0.797937\tvalid_1's auc: 0.788472\n",
      "[1192]\ttraining's auc: 0.797941\tvalid_1's auc: 0.788475\n",
      "[1193]\ttraining's auc: 0.797942\tvalid_1's auc: 0.788474\n",
      "[1194]\ttraining's auc: 0.797944\tvalid_1's auc: 0.788475\n",
      "[1195]\ttraining's auc: 0.797946\tvalid_1's auc: 0.788476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1196]\ttraining's auc: 0.797957\tvalid_1's auc: 0.788476\n",
      "[1197]\ttraining's auc: 0.797958\tvalid_1's auc: 0.788476\n",
      "[1198]\ttraining's auc: 0.79796\tvalid_1's auc: 0.788476\n",
      "[1199]\ttraining's auc: 0.797969\tvalid_1's auc: 0.788479\n",
      "[1200]\ttraining's auc: 0.797971\tvalid_1's auc: 0.788479\n",
      "[1201]\ttraining's auc: 0.797972\tvalid_1's auc: 0.788479\n",
      "[1202]\ttraining's auc: 0.797977\tvalid_1's auc: 0.788482\n",
      "[1203]\ttraining's auc: 0.797984\tvalid_1's auc: 0.788488\n",
      "[1204]\ttraining's auc: 0.797991\tvalid_1's auc: 0.788496\n",
      "[1205]\ttraining's auc: 0.797994\tvalid_1's auc: 0.788496\n",
      "[1206]\ttraining's auc: 0.798001\tvalid_1's auc: 0.788495\n",
      "[1207]\ttraining's auc: 0.798002\tvalid_1's auc: 0.788495\n",
      "[1208]\ttraining's auc: 0.798004\tvalid_1's auc: 0.788495\n",
      "[1209]\ttraining's auc: 0.798011\tvalid_1's auc: 0.788501\n",
      "[1210]\ttraining's auc: 0.798012\tvalid_1's auc: 0.788501\n",
      "[1211]\ttraining's auc: 0.798014\tvalid_1's auc: 0.788502\n",
      "[1212]\ttraining's auc: 0.798026\tvalid_1's auc: 0.788503\n",
      "[1213]\ttraining's auc: 0.798031\tvalid_1's auc: 0.788507\n",
      "[1214]\ttraining's auc: 0.798032\tvalid_1's auc: 0.788506\n",
      "[1215]\ttraining's auc: 0.798033\tvalid_1's auc: 0.788507\n",
      "[1216]\ttraining's auc: 0.798035\tvalid_1's auc: 0.788507\n",
      "[1217]\ttraining's auc: 0.798036\tvalid_1's auc: 0.788507\n",
      "[1218]\ttraining's auc: 0.798039\tvalid_1's auc: 0.788506\n",
      "[1219]\ttraining's auc: 0.798049\tvalid_1's auc: 0.788507\n",
      "[1220]\ttraining's auc: 0.798054\tvalid_1's auc: 0.788509\n",
      "[1221]\ttraining's auc: 0.798055\tvalid_1's auc: 0.788509\n",
      "[1222]\ttraining's auc: 0.798056\tvalid_1's auc: 0.788509\n",
      "[1223]\ttraining's auc: 0.798058\tvalid_1's auc: 0.78851\n",
      "[1224]\ttraining's auc: 0.798065\tvalid_1's auc: 0.788509\n",
      "[1225]\ttraining's auc: 0.798067\tvalid_1's auc: 0.788509\n",
      "[1226]\ttraining's auc: 0.798071\tvalid_1's auc: 0.788512\n",
      "[1227]\ttraining's auc: 0.798076\tvalid_1's auc: 0.788515\n",
      "[1228]\ttraining's auc: 0.798085\tvalid_1's auc: 0.788514\n",
      "[1229]\ttraining's auc: 0.798088\tvalid_1's auc: 0.788514\n",
      "[1230]\ttraining's auc: 0.798098\tvalid_1's auc: 0.788514\n",
      "[1231]\ttraining's auc: 0.7981\tvalid_1's auc: 0.788515\n",
      "[1232]\ttraining's auc: 0.798107\tvalid_1's auc: 0.788515\n",
      "[1233]\ttraining's auc: 0.798109\tvalid_1's auc: 0.788515\n",
      "[1234]\ttraining's auc: 0.798111\tvalid_1's auc: 0.788516\n",
      "[1235]\ttraining's auc: 0.798118\tvalid_1's auc: 0.788523\n",
      "[1236]\ttraining's auc: 0.79812\tvalid_1's auc: 0.788523\n",
      "[1237]\ttraining's auc: 0.798122\tvalid_1's auc: 0.788524\n",
      "[1238]\ttraining's auc: 0.798123\tvalid_1's auc: 0.788524\n",
      "[1239]\ttraining's auc: 0.798125\tvalid_1's auc: 0.788524\n",
      "[1240]\ttraining's auc: 0.798127\tvalid_1's auc: 0.788524\n",
      "[1241]\ttraining's auc: 0.798128\tvalid_1's auc: 0.788524\n",
      "[1242]\ttraining's auc: 0.798133\tvalid_1's auc: 0.788523\n",
      "[1243]\ttraining's auc: 0.798141\tvalid_1's auc: 0.788531\n",
      "[1244]\ttraining's auc: 0.798145\tvalid_1's auc: 0.78853\n",
      "[1245]\ttraining's auc: 0.798147\tvalid_1's auc: 0.788531\n",
      "[1246]\ttraining's auc: 0.798149\tvalid_1's auc: 0.788531\n",
      "[1247]\ttraining's auc: 0.798152\tvalid_1's auc: 0.78853\n",
      "[1248]\ttraining's auc: 0.798154\tvalid_1's auc: 0.78853\n",
      "[1249]\ttraining's auc: 0.798158\tvalid_1's auc: 0.788534\n",
      "[1250]\ttraining's auc: 0.798169\tvalid_1's auc: 0.788534\n",
      "[1251]\ttraining's auc: 0.798171\tvalid_1's auc: 0.788535\n",
      "[1252]\ttraining's auc: 0.798172\tvalid_1's auc: 0.788535\n",
      "[1253]\ttraining's auc: 0.798173\tvalid_1's auc: 0.788535\n",
      "[1254]\ttraining's auc: 0.798175\tvalid_1's auc: 0.788535\n",
      "[1255]\ttraining's auc: 0.798177\tvalid_1's auc: 0.788536\n",
      "[1256]\ttraining's auc: 0.798178\tvalid_1's auc: 0.788536\n",
      "[1257]\ttraining's auc: 0.79818\tvalid_1's auc: 0.788536\n",
      "[1258]\ttraining's auc: 0.798181\tvalid_1's auc: 0.788536\n",
      "[1259]\ttraining's auc: 0.798184\tvalid_1's auc: 0.788536\n",
      "[1260]\ttraining's auc: 0.79819\tvalid_1's auc: 0.788535\n",
      "[1261]\ttraining's auc: 0.798191\tvalid_1's auc: 0.788535\n",
      "[1262]\ttraining's auc: 0.798193\tvalid_1's auc: 0.788535\n",
      "[1263]\ttraining's auc: 0.798195\tvalid_1's auc: 0.788536\n",
      "[1264]\ttraining's auc: 0.798203\tvalid_1's auc: 0.788534\n",
      "[1265]\ttraining's auc: 0.798208\tvalid_1's auc: 0.788539\n",
      "[1266]\ttraining's auc: 0.798221\tvalid_1's auc: 0.788539\n",
      "[1267]\ttraining's auc: 0.798225\tvalid_1's auc: 0.788543\n",
      "[1268]\ttraining's auc: 0.798226\tvalid_1's auc: 0.788543\n",
      "[1269]\ttraining's auc: 0.798228\tvalid_1's auc: 0.788543\n",
      "[1270]\ttraining's auc: 0.79823\tvalid_1's auc: 0.788543\n",
      "[1271]\ttraining's auc: 0.798231\tvalid_1's auc: 0.788543\n",
      "[1272]\ttraining's auc: 0.798233\tvalid_1's auc: 0.788543\n",
      "[1273]\ttraining's auc: 0.798237\tvalid_1's auc: 0.788543\n",
      "[1274]\ttraining's auc: 0.798246\tvalid_1's auc: 0.788543\n",
      "[1275]\ttraining's auc: 0.798249\tvalid_1's auc: 0.788545\n",
      "[1276]\ttraining's auc: 0.798251\tvalid_1's auc: 0.788545\n",
      "[1277]\ttraining's auc: 0.798252\tvalid_1's auc: 0.788545\n",
      "[1278]\ttraining's auc: 0.798254\tvalid_1's auc: 0.788545\n",
      "[1279]\ttraining's auc: 0.798261\tvalid_1's auc: 0.788552\n",
      "[1280]\ttraining's auc: 0.798262\tvalid_1's auc: 0.788552\n",
      "[1281]\ttraining's auc: 0.798264\tvalid_1's auc: 0.788552\n",
      "[1282]\ttraining's auc: 0.798272\tvalid_1's auc: 0.788552\n",
      "[1283]\ttraining's auc: 0.798273\tvalid_1's auc: 0.788552\n",
      "[1284]\ttraining's auc: 0.798275\tvalid_1's auc: 0.788552\n",
      "[1285]\ttraining's auc: 0.798277\tvalid_1's auc: 0.788552\n",
      "[1286]\ttraining's auc: 0.798278\tvalid_1's auc: 0.788552\n",
      "[1287]\ttraining's auc: 0.79828\tvalid_1's auc: 0.788552\n",
      "[1288]\ttraining's auc: 0.798282\tvalid_1's auc: 0.788552\n",
      "[1289]\ttraining's auc: 0.798284\tvalid_1's auc: 0.788553\n",
      "[1290]\ttraining's auc: 0.798287\tvalid_1's auc: 0.788554\n",
      "[1291]\ttraining's auc: 0.798288\tvalid_1's auc: 0.788554\n",
      "[1292]\ttraining's auc: 0.79829\tvalid_1's auc: 0.788554\n",
      "[1293]\ttraining's auc: 0.798291\tvalid_1's auc: 0.788555\n",
      "[1294]\ttraining's auc: 0.798293\tvalid_1's auc: 0.788555\n",
      "[1295]\ttraining's auc: 0.798294\tvalid_1's auc: 0.788555\n",
      "[1296]\ttraining's auc: 0.798296\tvalid_1's auc: 0.788555\n",
      "[1297]\ttraining's auc: 0.798298\tvalid_1's auc: 0.788555\n",
      "[1298]\ttraining's auc: 0.7983\tvalid_1's auc: 0.788555\n",
      "[1299]\ttraining's auc: 0.798303\tvalid_1's auc: 0.788557\n",
      "[1300]\ttraining's auc: 0.798304\tvalid_1's auc: 0.788557\n",
      "[1301]\ttraining's auc: 0.79831\tvalid_1's auc: 0.788562\n",
      "[1302]\ttraining's auc: 0.798312\tvalid_1's auc: 0.788562\n",
      "[1303]\ttraining's auc: 0.798313\tvalid_1's auc: 0.788562\n",
      "[1304]\ttraining's auc: 0.798315\tvalid_1's auc: 0.788562\n",
      "[1305]\ttraining's auc: 0.798316\tvalid_1's auc: 0.788562\n",
      "[1306]\ttraining's auc: 0.798319\tvalid_1's auc: 0.788564\n",
      "[1307]\ttraining's auc: 0.79832\tvalid_1's auc: 0.788564\n",
      "[1308]\ttraining's auc: 0.798322\tvalid_1's auc: 0.788564\n",
      "[1309]\ttraining's auc: 0.798324\tvalid_1's auc: 0.788564\n",
      "[1310]\ttraining's auc: 0.798326\tvalid_1's auc: 0.788565\n",
      "[1311]\ttraining's auc: 0.798327\tvalid_1's auc: 0.788565\n",
      "[1312]\ttraining's auc: 0.798335\tvalid_1's auc: 0.788564\n",
      "[1313]\ttraining's auc: 0.798339\tvalid_1's auc: 0.788564\n",
      "[1314]\ttraining's auc: 0.798349\tvalid_1's auc: 0.788566\n",
      "[1315]\ttraining's auc: 0.79835\tvalid_1's auc: 0.788566\n",
      "[1316]\ttraining's auc: 0.798351\tvalid_1's auc: 0.788567\n",
      "[1317]\ttraining's auc: 0.798352\tvalid_1's auc: 0.788567\n",
      "[1318]\ttraining's auc: 0.798354\tvalid_1's auc: 0.788567\n",
      "[1319]\ttraining's auc: 0.798359\tvalid_1's auc: 0.788566\n",
      "[1320]\ttraining's auc: 0.798361\tvalid_1's auc: 0.788566\n",
      "[1321]\ttraining's auc: 0.798362\tvalid_1's auc: 0.788567\n",
      "[1322]\ttraining's auc: 0.798364\tvalid_1's auc: 0.788567\n",
      "[1323]\ttraining's auc: 0.798366\tvalid_1's auc: 0.788566\n",
      "[1324]\ttraining's auc: 0.798368\tvalid_1's auc: 0.788566\n",
      "[1325]\ttraining's auc: 0.798371\tvalid_1's auc: 0.788566\n",
      "[1326]\ttraining's auc: 0.798381\tvalid_1's auc: 0.788567\n",
      "[1327]\ttraining's auc: 0.798382\tvalid_1's auc: 0.788567\n",
      "[1328]\ttraining's auc: 0.798383\tvalid_1's auc: 0.788567\n",
      "[1329]\ttraining's auc: 0.798385\tvalid_1's auc: 0.788567\n",
      "[1330]\ttraining's auc: 0.798386\tvalid_1's auc: 0.788568\n",
      "[1331]\ttraining's auc: 0.798397\tvalid_1's auc: 0.788569\n",
      "[1332]\ttraining's auc: 0.798402\tvalid_1's auc: 0.788572\n",
      "[1333]\ttraining's auc: 0.798404\tvalid_1's auc: 0.788572\n",
      "[1334]\ttraining's auc: 0.798405\tvalid_1's auc: 0.788572\n",
      "[1335]\ttraining's auc: 0.798411\tvalid_1's auc: 0.788575\n",
      "[1336]\ttraining's auc: 0.798412\tvalid_1's auc: 0.788575\n",
      "[1337]\ttraining's auc: 0.798417\tvalid_1's auc: 0.788579\n",
      "[1338]\ttraining's auc: 0.798419\tvalid_1's auc: 0.788579\n",
      "[1339]\ttraining's auc: 0.798422\tvalid_1's auc: 0.78858\n",
      "[1340]\ttraining's auc: 0.798423\tvalid_1's auc: 0.78858\n",
      "[1341]\ttraining's auc: 0.798425\tvalid_1's auc: 0.78858\n",
      "[1342]\ttraining's auc: 0.798426\tvalid_1's auc: 0.78858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1343]\ttraining's auc: 0.798435\tvalid_1's auc: 0.78858\n",
      "[1344]\ttraining's auc: 0.798436\tvalid_1's auc: 0.78858\n",
      "[1345]\ttraining's auc: 0.79844\tvalid_1's auc: 0.788582\n",
      "[1346]\ttraining's auc: 0.798442\tvalid_1's auc: 0.788582\n",
      "[1347]\ttraining's auc: 0.798443\tvalid_1's auc: 0.788582\n",
      "[1348]\ttraining's auc: 0.798445\tvalid_1's auc: 0.788584\n",
      "[1349]\ttraining's auc: 0.79845\tvalid_1's auc: 0.788586\n",
      "[1350]\ttraining's auc: 0.798452\tvalid_1's auc: 0.788586\n",
      "[1351]\ttraining's auc: 0.798454\tvalid_1's auc: 0.788586\n",
      "[1352]\ttraining's auc: 0.798455\tvalid_1's auc: 0.788586\n",
      "[1353]\ttraining's auc: 0.798457\tvalid_1's auc: 0.788586\n",
      "[1354]\ttraining's auc: 0.798458\tvalid_1's auc: 0.788587\n",
      "[1355]\ttraining's auc: 0.79846\tvalid_1's auc: 0.788587\n",
      "[1356]\ttraining's auc: 0.798462\tvalid_1's auc: 0.788587\n",
      "[1357]\ttraining's auc: 0.798463\tvalid_1's auc: 0.788587\n",
      "[1358]\ttraining's auc: 0.798465\tvalid_1's auc: 0.788587\n",
      "[1359]\ttraining's auc: 0.798466\tvalid_1's auc: 0.788587\n",
      "[1360]\ttraining's auc: 0.798468\tvalid_1's auc: 0.788588\n",
      "[1361]\ttraining's auc: 0.798469\tvalid_1's auc: 0.788588\n",
      "[1362]\ttraining's auc: 0.798471\tvalid_1's auc: 0.788588\n",
      "[1363]\ttraining's auc: 0.798473\tvalid_1's auc: 0.788588\n",
      "[1364]\ttraining's auc: 0.798474\tvalid_1's auc: 0.788588\n",
      "[1365]\ttraining's auc: 0.798476\tvalid_1's auc: 0.788588\n",
      "[1366]\ttraining's auc: 0.798478\tvalid_1's auc: 0.788588\n",
      "[1367]\ttraining's auc: 0.798484\tvalid_1's auc: 0.78859\n",
      "[1368]\ttraining's auc: 0.798486\tvalid_1's auc: 0.78859\n",
      "[1369]\ttraining's auc: 0.798491\tvalid_1's auc: 0.788594\n",
      "[1370]\ttraining's auc: 0.798493\tvalid_1's auc: 0.788595\n",
      "[1371]\ttraining's auc: 0.798497\tvalid_1's auc: 0.788597\n",
      "[1372]\ttraining's auc: 0.798504\tvalid_1's auc: 0.788597\n",
      "[1373]\ttraining's auc: 0.798505\tvalid_1's auc: 0.788597\n",
      "[1374]\ttraining's auc: 0.798512\tvalid_1's auc: 0.788598\n",
      "[1375]\ttraining's auc: 0.798514\tvalid_1's auc: 0.788598\n",
      "[1376]\ttraining's auc: 0.798516\tvalid_1's auc: 0.788599\n",
      "[1377]\ttraining's auc: 0.79852\tvalid_1's auc: 0.788602\n",
      "[1378]\ttraining's auc: 0.798522\tvalid_1's auc: 0.788602\n",
      "[1379]\ttraining's auc: 0.798524\tvalid_1's auc: 0.788603\n",
      "[1380]\ttraining's auc: 0.798525\tvalid_1's auc: 0.788603\n",
      "[1381]\ttraining's auc: 0.798526\tvalid_1's auc: 0.788603\n",
      "[1382]\ttraining's auc: 0.798528\tvalid_1's auc: 0.788603\n",
      "[1383]\ttraining's auc: 0.798535\tvalid_1's auc: 0.788601\n",
      "[1384]\ttraining's auc: 0.798537\tvalid_1's auc: 0.788602\n",
      "[1385]\ttraining's auc: 0.798538\tvalid_1's auc: 0.788602\n",
      "[1386]\ttraining's auc: 0.79854\tvalid_1's auc: 0.788602\n",
      "[1387]\ttraining's auc: 0.798541\tvalid_1's auc: 0.788602\n",
      "[1388]\ttraining's auc: 0.798546\tvalid_1's auc: 0.788605\n",
      "[1389]\ttraining's auc: 0.798547\tvalid_1's auc: 0.788605\n",
      "[1390]\ttraining's auc: 0.798549\tvalid_1's auc: 0.788605\n",
      "[1391]\ttraining's auc: 0.79855\tvalid_1's auc: 0.788605\n",
      "[1392]\ttraining's auc: 0.798552\tvalid_1's auc: 0.788605\n",
      "[1393]\ttraining's auc: 0.798553\tvalid_1's auc: 0.788605\n",
      "[1394]\ttraining's auc: 0.798554\tvalid_1's auc: 0.788605\n",
      "[1395]\ttraining's auc: 0.798556\tvalid_1's auc: 0.788605\n",
      "[1396]\ttraining's auc: 0.798558\tvalid_1's auc: 0.788605\n",
      "[1397]\ttraining's auc: 0.798559\tvalid_1's auc: 0.788605\n",
      "[1398]\ttraining's auc: 0.798561\tvalid_1's auc: 0.788605\n",
      "[1399]\ttraining's auc: 0.798562\tvalid_1's auc: 0.788605\n",
      "[1400]\ttraining's auc: 0.798564\tvalid_1's auc: 0.788605\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1400]\ttraining's auc: 0.798564\tvalid_1's auc: 0.788605\n",
      "Training done!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,num):\n",
    "      \n",
    "#     tr_data = lgb.Dataset(trains[i][features], label=trains[i][target])\n",
    "#     va_data = lgb.Dataset(valids[i][features], label=valids[i][target])\n",
    "\n",
    "    #Don't use DF to create lightgbm dataset, rather use np array:\n",
    "    X_train_np = trains[i][features].values.astype(np.float32)\n",
    "    X_valid_np = valids[i][features].values.astype(np.float32)\n",
    "    #features = train.columns\n",
    "    tr_data = lgb.Dataset(X_train_np, label=trains[i][target], feature_name=list(features))\n",
    "    va_data = lgb.Dataset(X_valid_np, label=valids[i][target], feature_name=list(features))\n",
    "    \n",
    "\n",
    "#     del train_df_clf\n",
    "#     del valid_df\n",
    "#     gc.collect()\n",
    "    del trains\n",
    "    del valids\n",
    "    del X_train_np\n",
    "    del X_valid_np\n",
    "    gc.collect()\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        tr_data,\n",
    "#         train_df[features],\n",
    "#         train_df[target],\n",
    "        num_boost_round=1400,\n",
    "        #valid_sets=[(train_df[features],train_df[target]), (valid_df[features],valid_df[target])], \n",
    "        valid_sets=[tr_data, va_data],\n",
    "        early_stopping_rounds=20,\n",
    "        feature_name=features,\n",
    "        categorical_feature=categorical_columns,\n",
    "        verbose_eval=1\n",
    "    )\n",
    "    clfs.append(model)\n",
    "    print('Training done!!!')\n",
    "    #print('test-auc:', roc_auc_score(test_df[target], model.predict(test_df[features])))\n",
    "    #model.save_model(f'model.txt')\n",
    "\n",
    "\n",
    "#     fig,ax = plt.subplots(figsize=(15,15))\n",
    "#     lgb.plot_importance(model, ax=ax,importance_type='gain',max_num_features=50)\n",
    "#     plt.show()\n",
    "\n",
    "    del tr_data\n",
    "    del va_data\n",
    "    gc.collect()\n",
    "#    \n",
    "# del trains\n",
    "# del valids\n",
    "# gc.collect()\n",
    "# del test_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.472814e+07</td>\n",
       "      <td>content_explation_true_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.361779e+07</td>\n",
       "      <td>content_correctness_std</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.671660e+07</td>\n",
       "      <td>content_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.001365e+07</td>\n",
       "      <td>user_part_correctness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.896011e+07</td>\n",
       "      <td>part_bundle_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.879862e+07</td>\n",
       "      <td>user_correctness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.168947e+06</td>\n",
       "      <td>content_lagtime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.834301e+06</td>\n",
       "      <td>content_uncorrect_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.579026e+06</td>\n",
       "      <td>lagtime_in_lecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.485326e+06</td>\n",
       "      <td>attempt_no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.802343e+06</td>\n",
       "      <td>part_lagtime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.503018e+06</td>\n",
       "      <td>lagtime1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.858420e+06</td>\n",
       "      <td>user_correct_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.578163e+06</td>\n",
       "      <td>part_correctness_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.272353e+06</td>\n",
       "      <td>prior_question_elapsed_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.251059e+06</td>\n",
       "      <td>lagtime3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.166571e+06</td>\n",
       "      <td>content_correct_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.657226e+06</td>\n",
       "      <td>content_had_explanation_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546093e+06</td>\n",
       "      <td>lagtime2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.252570e+06</td>\n",
       "      <td>explanation_false_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.034691e+06</td>\n",
       "      <td>lagtime2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.886538e+05</td>\n",
       "      <td>attempt_no_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.581599e+05</td>\n",
       "      <td>user_lecture_lv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.662036e+05</td>\n",
       "      <td>user_lecture_sum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Value                       Feature\n",
       "10  5.472814e+07   content_explation_true_mean\n",
       "6   3.361779e+07       content_correctness_std\n",
       "2   2.671660e+07                    content_id\n",
       "20  2.001365e+07         user_part_correctness\n",
       "13  1.896011e+07                part_bundle_id\n",
       "4   1.879862e+07              user_correctness\n",
       "16  8.168947e+06               content_lagtime\n",
       "8   7.834301e+06       content_uncorrect_count\n",
       "15  7.579026e+06            lagtime_in_lecture\n",
       "11  5.485326e+06                    attempt_no\n",
       "21  3.802343e+06                  part_lagtime\n",
       "18  3.503018e+06                    lagtime1_2\n",
       "5   2.858420e+06            user_correct_count\n",
       "12  2.578163e+06         part_correctness_mean\n",
       "3   2.272353e+06   prior_question_elapsed_time\n",
       "1   2.251059e+06                      lagtime3\n",
       "7   2.166571e+06         content_correct_count\n",
       "9   1.657226e+06  content_had_explanation_mean\n",
       "0   1.546093e+06                      lagtime2\n",
       "14  1.252570e+06       explanation_false_count\n",
       "19  1.034691e+06                    lagtime2_3\n",
       "17  7.886538e+05               attempt_no_mean\n",
       "23  6.581599e+05               user_lecture_lv\n",
       "22  4.662036e+05              user_lecture_sum"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(zip(clfs[0].feature_importance(importance_type='gain'), features), columns=['Value', 'Feature'])\n",
    "tmp.sort_values('Value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lightgbm.basic.Booster'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clfs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    " from sklearn.externals import joblib\n",
    "# save model\n",
    "joblib.dump(clfs[0], 'lgb2.pkl')\n",
    "# load model\n",
    "model = joblib.load('lgb2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lightgbm.basic.Booster'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
